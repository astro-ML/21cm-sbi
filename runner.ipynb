{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summary_models import *\n",
    "from cl_models import RNVP, NSF_CL\n",
    "from ar_models import NSF_AR, MAF\n",
    "from classifier import ResNet\n",
    "from plot import pairplot\n",
    "from dataloader import *\n",
    "from torch.utils.data import DataLoader\n",
    "from NLE import NLEHandler\n",
    "from NPE import NPEHandler\n",
    "from NRE import NREHandler\n",
    "from Trainer import SNHandler, Trainer\n",
    "from analysis import Analysis\n",
    "#my_module_path = os.path.join(\"../\", '21cm-wrappe}r')\n",
    "#sys.path.append(my_module_path)\n",
    "#from Leaf import * \n",
    "#from sbi import analysis\n",
    "from ray import tune\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = 'cpu'\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork', force=True)\n",
    "#torch.set_num_interop_threads(4) # Inter-op parallelism\n",
    "#torch.set_num_threads(6) # Intra-op parallelism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: torch.Size([1, 48, 14, 14, 20])\n",
      "2: torch.Size([1, 48, 7, 7, 10])\n",
      "3: torch.Size([1, 64, 3, 3, 5])\n",
      "4: torch.Size([1, 96, 1, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4523, 0.5209, 0.4834, 0.4714, 0.4913, 0.5314]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Summary_net_lc_smol()\n",
    "net(torch.rand(1,1,28,28,680), torch.rand(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Succesfully initialized SNHandler\n",
      "INFO: Succesfully initialized NPEHandler\n",
      "INFO: Succesfully initialized NLEHandler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/remote/gpu01a/schlenker/21cm-sbi/NPE.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.density_estimator.load_state_dict(torch.load(path + \"density_model.pt\", map_location=torch.device(self.device)))\n",
      "/remote/gpu01a/schlenker/21cm-sbi/Trainer.py:450: DeprecationWarning: invalid escape sequence '\\d'\n",
      "  \"\"\"class RecNetHandler(SNHandler):\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './density_model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 105\u001b[0m\n\u001b[1;32m     89\u001b[0m model_de \u001b[38;5;241m=\u001b[39m NLEHandler(density_estimator\u001b[38;5;241m=\u001b[39mMAF, \n\u001b[1;32m     90\u001b[0m                       density_estimator_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     91\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m                     },\n\u001b[1;32m     97\u001b[0m                       device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     99\u001b[0m model \u001b[38;5;241m=\u001b[39m Trainer(NetworkHandlerDE\u001b[38;5;241m=\u001b[39mmodel_de,\n\u001b[1;32m    100\u001b[0m                 NetworkHandlerSN\u001b[38;5;241m=\u001b[39mmodel_sn,\n\u001b[1;32m    101\u001b[0m                 training_data\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m    102\u001b[0m                 test_data\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m    103\u001b[0m                 device\u001b[38;5;241m=\u001b[39mdevice,)\n\u001b[0;32m--> 105\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m#model_sn(torch.rand(2,6))\u001b[39;00m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/Trainer.py:223\u001b[0m, in \u001b[0;36mTrainer.load_model\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mde_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mde_net\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mde_net\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/NPE.py:47\u001b[0m, in \u001b[0;36mNPEHandler.load\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdensity_estimator\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdensity_model.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdensity_estimator\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdensity_estimator\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './density_model.pt'"
     ]
    }
   ],
   "source": [
    "from summary_models import *\n",
    "from cl_models import RNVP, NSF_CL\n",
    "from ar_models import NSF_AR, MAF\n",
    "from classifier import ResNet\n",
    "from plot import pairplot\n",
    "from dataloader import *\n",
    "from torch.utils.data import DataLoader\n",
    "from NLE import NLEHandler\n",
    "from NPE import NPEHandler\n",
    "from NRE import NREHandler\n",
    "from Trainer import SNHandler, Trainer\n",
    "from analysis import Analysis\n",
    "#my_module_path = os.path.join(\"../\", '21cm-wrappe}r')\n",
    "#sys.path.append(my_module_path)\n",
    "#from Leaf import * \n",
    "#from sbi import analysis\n",
    "from ray import tune\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork', force=True)\n",
    "#torch.set_num_interop_threads(4) # Inter-op parallelism\n",
    "#torch.set_num_threads(6) # Intra-op parallelism\n",
    "\n",
    "\n",
    "# hyperparams\n",
    "data_path = \"/remote/gpu01a/schlenker/archive/datax5/\"\n",
    "batch_size = 32\n",
    "epochs = 60\n",
    "train_test_data_ration = 0.8\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "optimizer_params = {\n",
    "    \"lr\": 7e-4,\n",
    "}\n",
    "\n",
    "\n",
    "loss = torch.nn.MSELoss\n",
    "loss_params = {}\n",
    "\n",
    "norm_range = torch.tensor([\n",
    "            [0.3,10.0], # M_WDM\n",
    "            [0.2,0.4], # OMm\n",
    "            [38, 42], # L_X\n",
    "            [100, 1500], # NU_X_THRESH\n",
    "            [4, 5.3], # ION_Tvir_MIN\n",
    "            [10.0, 250.0], # HII_EFF_FACTOR\n",
    "], dtype = torch.float32)\n",
    "\n",
    "\n",
    "# transform trainingsdata\n",
    "# perhaps add check if file is there: continue + override option in the future\n",
    "#convert_to_torch(path = data_path, prefix=\"run\", redshift_cutoff=600, debug=False, statistics=True)\n",
    "#noise_model = mock_noise(\"/home/allomere/Documents/projects/master/21cm_pie\")\n",
    "# load data\n",
    "train_data = DataHandler(path=data_path, prefix=\"batch_\",\n",
    "                         split = train_test_data_ration, training_data = True, expand_dim = True,\n",
    "                         apply_norm=True, norm_range=norm_range, augmentation_probability=0.5, psvar=False)\n",
    "test_data = DataHandler(path=data_path, prefix=\"batch_\",\n",
    "                         split = train_test_data_ration, training_data = False, expand_dim = True,\n",
    "                         apply_norm=True, norm_range=norm_range, augmentation_probability=0, psvar=False)\n",
    "# import data to torch dataloader\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                              num_workers = 0, pin_memory = True, prefetch_factor=None)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=True,\n",
    "                             num_workers = 0, pin_memory = True, prefetch_factor=None)\n",
    "\n",
    "# init model\n",
    "model_sn = SNHandler(encoder=Summary_net_lc_super_smol, decoder=Summary_net_lc_super_smol_inv, device=device,)\n",
    "#model_rec = RecNetHandler(Model = global_temp_smol_inv_super_smol, summary_net = model_sn.Model, device=device)\n",
    "#summary(model_sn.Model, [(10,9), (2,)])\n",
    "# traind\n",
    "'''\n",
    "loss_tmp= model_sn.training(\n",
    "    training_data = train_dataloader,\n",
    "    test_data = test_dataloader,\n",
    "    epochs=epochs,\n",
    "    config = {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"optimizer_kwargs\": optimizer_params,\n",
    "    },\n",
    "    )\n",
    "model_sn.plot(\"training_fff_test\")\n",
    "model_sn.save(\"./\")\n",
    "'''\n",
    "model_de = NLEHandler(density_estimator=MAF, \n",
    "                      density_estimator_kwargs={\n",
    "                        \"n_blocks\": 6,\n",
    "                        \"in_dim\": 6,\n",
    "                        \"hidden_layer\": 2,\n",
    "                        \"n_nodes\": 64,\n",
    "                        \"activation\": 'gelu',\n",
    "                    },\n",
    "                      device=device)\n",
    "\n",
    "model = Trainer(NetworkHandlerDE=model_de,\n",
    "                NetworkHandlerSN=model_sn,\n",
    "                training_data=train_dataloader,\n",
    "                test_data=test_dataloader,\n",
    "                device=device,)\n",
    "\n",
    "model.load_model(\"./\")\n",
    "#model_sn(torch.rand(2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|▶▶▶▶▶▶▶▶▶▶▶▶▶▶                          | ▁▃▅ 0 in 0s (0.0/s) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "on 0: /remote/gpu01a/schlenker/21cm-sbi/dataloader.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "        images = torch.tensor(images)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████| 0 in 2.1s (0.00/s)                   \n",
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/sbi/inference/posteriors/mcmc_posterior.py:115: UserWarning: The default value for thinning in MCMC sampling has been changed from 10 to 1. This might cause the results differ from the last benchmark.\n",
      "  thin = _process_thin_default(thin)\n",
      "/remote/gpu01a/schlenker/21cm-sbi/analysis.py:32: DeprecationWarning: invalid escape sequence '\\O'\n",
      "  \"\"\"Class to analyse a neural posterior (NPE) estimator on several metrics.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m ana \u001b[38;5;241m=\u001b[39m Analysis(Trainer\u001b[38;5;241m=\u001b[39mmodel, Validation_Dataset\u001b[38;5;241m=\u001b[39mtest_dataloader, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoint_test_beta1\u001b[39m\u001b[38;5;124m\"\u001b[39m, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m                posterior_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_with\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcmc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice_np_vectorized\u001b[39m\u001b[38;5;124m\"\u001b[39m,})\n\u001b[0;32m----> 4\u001b[0m \u001b[43mana\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarginals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples_stat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/analysis.py:84\u001b[0m, in \u001b[0;36mAnalysis.marginals\u001b[0;34m(self, num_points, num_samples_stat)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 84\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mde_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples_stat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# plot posterior samples\u001b[39;00m\n\u001b[1;32m     86\u001b[0m figure, axis \u001b[38;5;241m=\u001b[39m pairplot(samples \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), points\u001b[38;5;241m=\u001b[39mlab\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m     87\u001b[0m     limits\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m],[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m],[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m],[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m],[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m],[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m],], figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m     88\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels,\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m#quantiles=((0.16, 0.84, 0.0015, 0.99815)), levels=(1 - np.exp(-0.5),1 - np.exp(-9/2)),\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     upper \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m'\u001b[39m, lower \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontour\u001b[39m\u001b[38;5;124m'\u001b[39m, diag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkde\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/NLE.py:20\u001b[0m, in \u001b[0;36mNLEHandler.sample\u001b[0;34m(self, num_samples, x, sample_kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdensity_estimator\u001b[38;5;241m.\u001b[39mbuild_posterior(sample_kwargs)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior_constructed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdensity_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/ar_models.py:283\u001b[0m, in \u001b[0;36mMAF.sample\u001b[0;34m(self, num_samples, x, sample_kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_samples, x, sample_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreversed:\n\u001b[0;32m--> 283\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m    \n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m         u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_dist\u001b[38;5;241m.\u001b[39msample((num_samples,))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/sbi/inference/posteriors/mcmc_posterior.py:318\u001b[0m, in \u001b[0;36mMCMCPosterior.sample\u001b[0;34m(self, sample_shape, x, method, thin, warmup_steps, num_chains, init_strategy, init_strategy_parameters, init_strategy_num_candidates, mcmc_parameters, mcmc_method, sample_with, num_workers, mp_context, show_progress_bars)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(track_gradients):\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice_np\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice_np_vectorized\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 318\u001b[0m         transformed_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_np_mcmc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpotential_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpotential_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m            \u001b[49m\u001b[43mthin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    323\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvectorized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslice_np_vectorized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m            \u001b[49m\u001b[43minterchangeable_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshow_progress_bars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhmc_pyro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnuts_pyro\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    330\u001b[0m         transformed_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pyro_mcmc(\n\u001b[1;32m    331\u001b[0m             num_samples\u001b[38;5;241m=\u001b[39mnum_samples,\n\u001b[1;32m    332\u001b[0m             potential_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpotential_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m             mp_context\u001b[38;5;241m=\u001b[39mmp_context,\n\u001b[1;32m    340\u001b[0m         )\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/sbi/inference/posteriors/mcmc_posterior.py:753\u001b[0m, in \u001b[0;36mMCMCPosterior._slice_np_mcmc\u001b[0;34m(self, num_samples, potential_function, initial_params, thin, warmup_steps, vectorized, interchangeable_chains, num_workers, init_width, show_progress_bars)\u001b[0m\n\u001b[1;32m    751\u001b[0m num_samples_ \u001b[38;5;241m=\u001b[39m ceil((num_samples \u001b[38;5;241m*\u001b[39m thin) \u001b[38;5;241m/\u001b[39m num_chains)\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# Run mcmc including warmup\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mposterior_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwarmup_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_samples_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m samples \u001b[38;5;241m=\u001b[39m samples[:, warmup_steps:, :]  \u001b[38;5;66;03m# discard warmup steps\u001b[39;00m\n\u001b[1;32m    755\u001b[0m samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(samples)  \u001b[38;5;66;03m# chains x samples x dim\u001b[39;00m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/sbi/samplers/mcmc/slice_numpy.py:462\u001b[0m, in \u001b[0;36mSliceSamplerVectorized.run\u001b[0;34m(self, num_samples)\u001b[0m\n\u001b[1;32m    455\u001b[0m         sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_param\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\n\u001b[1;32m    456\u001b[0m             sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m][: sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m\"\u001b[39m][sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m]]],\n\u001b[1;32m    457\u001b[0m             [sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcxi\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m    458\u001b[0m             sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m][sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m\"\u001b[39m][sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :],\n\u001b[1;32m    459\u001b[0m         ])\n\u001b[1;32m    461\u001b[0m params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_param\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mvalues()])\n\u001b[0;32m--> 462\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_chains):\n\u001b[1;32m    465\u001b[0m     sc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[c]\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/sbi/inference/posteriors/mcmc_posterior.py:738\u001b[0m, in \u001b[0;36mMCMCPosterior._slice_np_mcmc.<locals>.multi_obs_potential\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmulti_obs_potential\u001b[39m(params):\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;66;03m# Params are of shape (num_chains * num_obs, event).\u001b[39;00m\n\u001b[0;32m--> 738\u001b[0m     all_potentials \u001b[38;5;241m=\u001b[39m \u001b[43mpotential_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (num_chains, num_obs)\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_potentials\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/sbi/utils/potentialutils.py:44\u001b[0m, in \u001b[0;36mtransformed_potential\u001b[0;34m(theta, potential_fn, theta_transform, device, track_gradients)\u001b[0m\n\u001b[1;32m     41\u001b[0m theta \u001b[38;5;241m=\u001b[39m theta_transform\u001b[38;5;241m.\u001b[39minv(transformed_theta)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     42\u001b[0m log_abs_det \u001b[38;5;241m=\u001b[39m theta_transform\u001b[38;5;241m.\u001b[39mlog_abs_det_jacobian(theta, transformed_theta)\n\u001b[0;32m---> 44\u001b[0m posterior_potential \u001b[38;5;241m=\u001b[39m \u001b[43mpotential_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m posterior_potential_transformed \u001b[38;5;241m=\u001b[39m posterior_potential \u001b[38;5;241m-\u001b[39m log_abs_det\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m posterior_potential_transformed\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/sbi/inference/potentials/likelihood_based_potential.py:95\u001b[0m, in \u001b[0;36mLikelihoodBasedPotential.__call__\u001b[0;34m(self, theta, track_gradients)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the potential $\\log(p(x_o|\\theta)p(\\theta))$.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    The potential $\\log(p(x_o|\\theta)p(\\theta))$.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_is_iid:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# For each theta, calculate the likelihood sum over all x in batch.\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     log_likelihood_trial_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_log_likelihoods_over_trials\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_o\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrack_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_likelihood_trial_sum \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39mlog_prob(theta)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Calculate likelihood for each (theta,x) pair separately\u001b[39;00m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/sbi/inference/potentials/likelihood_based_potential.py:168\u001b[0m, in \u001b[0;36m_log_likelihoods_over_trials\u001b[0;34m(x, theta, estimator, track_gradients)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Calculate likelihood in one batch.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(track_gradients):\n\u001b[0;32m--> 168\u001b[0m     log_likelihood_trial_batch \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Sum over trial-log likelihoods.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     log_likelihood_trial_sum \u001b[38;5;241m=\u001b[39m log_likelihood_trial_batch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/ar_models.py:261\u001b[0m, in \u001b[0;36mMAF.log_prob\u001b[0;34m(self, x, condition)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of x is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but is expected to be (sample_shape, batch_shape, event_shape) or (batch_shape, event_shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# only there to handle weird sbi package stuff\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m#print(x.shape, condition.shape)\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m s, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xshape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    264\u001b[0m     p \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreshape(xshape[\u001b[38;5;241m0\u001b[39m], xshape[\u001b[38;5;241m1\u001b[39m], xshape[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/ar_models.py:248\u001b[0m, in \u001b[0;36mMAF.forward\u001b[0;34m(self, x, cond)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, cond\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/made_backbone.py:135\u001b[0m, in \u001b[0;36mFlowSequential.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    133\u001b[0m sum_log_abs_det_jacobians \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m     x, log_abs_det_jacobian \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     sum_log_abs_det_jacobians \u001b[38;5;241m=\u001b[39m sum_log_abs_det_jacobians \u001b[38;5;241m+\u001b[39m log_abs_det_jacobian\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, sum_log_abs_det_jacobians\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/made_backbone.py:195\u001b[0m, in \u001b[0;36mMADE.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# MAF eq 4 -- return mean and log std\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     m, loga \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(chunks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    196\u001b[0m     u \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m m) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mloga)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# MAF eq 5\u001b[39;00m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/made_backbone.py:51\u001b[0m, in \u001b[0;36mMaskedLinear.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 51\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m         out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcond_weight)\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ana = Analysis(Trainer=model, Validation_Dataset=test_dataloader, filename=\"joint_test_beta1\", path=\"./\",\n",
    "               posterior_kwargs={'sample_with': 'mcmc',\n",
    "                                 \"method\": \"slice_np_vectorized\",})\n",
    "ana.marginals(num_samples_stat=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for the summary_net_lc_smol\n",
    "init_layers = {\n",
    "    \"layer_size1\": 1,\n",
    "    \"channel1\": 48,\n",
    "    \"kernel_size1_xy\": 3,\n",
    "    \"kernel_size1_z\": 47,\n",
    "    \n",
    "    \"layer_size2\": 1,\n",
    "    \"channel2\": 48,\n",
    "    \"kernel_size2\": 3,\n",
    "    \n",
    "    \"layer_size3\": 1,\n",
    "    \"channel3\": 64,\n",
    "    \"kernel_size3\": 3,\n",
    "    \n",
    "    \"layer_size4\": 1,\n",
    "    \"channel4\": 96,\n",
    "    \"kernel_size4\": 3,\n",
    "}\n",
    "\n",
    "# Initialize the summary_net_lc_smol with the given configuration\n",
    "summary_net = Summary_net_lc_super_smol_inv()\n",
    "\n",
    "# Print the summary of the model to verify the configuration\n",
    "summary(summary_net, input_size=[(1, 6),(1,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Succesfully initialized SNHandler\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'loss_tmp= model_sn.training(\\n    training_data = train_dataloader,\\n    test_data = test_dataloader,\\n    epochs=epochs,\\n    config = {\\n        \"optimizer\": optimizer,\\n        \"optimizer_kwargs\": optimizer_params,\\n    },\\n    )\\nmodel_sn.plot(\"training_sn_test\")\\nmodel_sn.save(\"./\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparams\n",
    "data_path = \"/remote/gpu01a/schlenker/archive/datax5/\"\n",
    "batch_size = 16\n",
    "epochs = 40\n",
    "train_test_data_ration = 0.8\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "optimizer_params = {\n",
    "    \"lr\": 1e-3,\n",
    "}\n",
    "\n",
    "\n",
    "loss = torch.nn.MSELoss\n",
    "loss_params = {}\n",
    "\n",
    "norm_range = torch.tensor([\n",
    "            [0.3,10.0], # M_WDM\n",
    "            [0.2,0.4], # OMm\n",
    "            [38, 42], # L_X\n",
    "            [100, 1500], # NU_X_THRESH\n",
    "            [4, 5.3], # ION_Tvir_MIN\n",
    "            [10.0, 250.0], # HII_EFF_FACTOR\n",
    "], dtype = torch.float32)\n",
    "\n",
    "\n",
    "# transform trainingsdata\n",
    "# perhaps add check if file is there: continue + override option in the future\n",
    "#convert_to_torch(path = data_path, prefix=\"run\", redshift_cutoff=600, debug=False, statistics=True)\n",
    "#noise_model = mock_noise(\"/home/allomere/Documents/projects/master/21cm_pie\")\n",
    "# load data\n",
    "train_data = DataHandler(path=data_path, prefix=\"batch_\",\n",
    "                         split = train_test_data_ration, training_data = True, expand_dim = True,\n",
    "                         apply_norm=True, norm_range=norm_range, augmentation_probability=0.5, psvar=False)\n",
    "test_data = DataHandler(path=data_path, prefix=\"batch_\",\n",
    "                         split = train_test_data_ration, training_data = False, expand_dim = True,\n",
    "                         apply_norm=True, norm_range=norm_range, augmentation_probability=0, psvar=False)\n",
    "# import data to torch dataloader\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                              num_workers = 0, pin_memory = True, prefetch_factor=None)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=True,\n",
    "                             num_workers = 0, pin_memory = True, prefetch_factor=None)\n",
    "\n",
    "# init model\n",
    "model_sn = SNHandler(encoder=Summary_net_lc_super_smol, device=device,)\n",
    "#model_rec = RecNetHandler(Model = global_temp_smol_inv_super_smol, summary_net = model_sn.Model, device=device)\n",
    "#summary(model_sn.Model, [(10,9), (2,)])\n",
    "# traind\n",
    "'''loss_tmp= model_sn.training(\n",
    "    training_data = train_dataloader,\n",
    "    test_data = test_dataloader,\n",
    "    epochs=epochs,\n",
    "    config = {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"optimizer_kwargs\": optimizer_params,\n",
    "    },\n",
    "    )\n",
    "model_sn.plot(\"training_sn_test\")\n",
    "model_sn.save(\"./\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Succesfully initialized NPEHandler\n",
      "INFO: Succesfully initialized SNHandler\n",
      "/remote/gpu01a/schlenker/21cm-sbi/Trainer.py:430: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.encoder.load_state_dict(torch.load(path + \"encoder.pt\", map_location=torch.device(self.device)))\n",
      "INFO: No gradient clipping\n",
      "INFO: Initialize optimizer for density estimator training with freezed summary...\n",
      "INFO: Begin training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "on 0: /remote/gpu01a/schlenker/21cm-sbi/dataloader.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "        images = torch.tensor(images)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|⚠︎                                       | (!) 0/10 [0%] in 1.8s (0.00/s)       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/remote/gpu01a/schlenker/21cm-sbi/Trainer.py:450: DeprecationWarning: invalid escape sequence '\\d'\n",
      "  \"\"\"class RecNetHandler(SNHandler):\n",
      "/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/FrEIA/modules/all_in_one_block.py:54: DeprecationWarning: invalid escape sequence '\\m'\n",
      "  '''\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m\n\u001b[1;32m     29\u001b[0m summary_net\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m sbi \u001b[38;5;241m=\u001b[39m Trainer(NetworkHandlerDE \u001b[38;5;241m=\u001b[39m density_model, NetworkHandlerSN \u001b[38;5;241m=\u001b[39m summary_net, \n\u001b[1;32m     32\u001b[0m               training_data\u001b[38;5;241m=\u001b[39mtrain_dataloader, test_data\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m     33\u001b[0m                 device \u001b[38;5;241m=\u001b[39m device)\n\u001b[0;32m---> 35\u001b[0m \u001b[43msbi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_clip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_kwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreezed_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreezed_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m sbi\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpe.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m ana \u001b[38;5;241m=\u001b[39m Analysis(sbi, test_dataloader, device)\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/Trainer.py:126\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, config, epochs, pretrain_epochs, freezed_epochs)\u001b[0m\n\u001b[1;32m    124\u001b[0m losssn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msn_net\u001b[38;5;241m.\u001b[39mloss(img, lab, rnge)\n\u001b[1;32m    125\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msn_net\u001b[38;5;241m.\u001b[39mencoder(img, rnge)\n\u001b[0;32m--> 126\u001b[0m loss_de \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mde_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnge\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dec:\n\u001b[1;32m    128\u001b[0m     loss \u001b[38;5;241m=\u001b[39m losssn\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/NPE.py:53\u001b[0m, in \u001b[0;36mNPEHandler.loss\u001b[0;34m(self, img, lab, rnge)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, lab, rnge):                  \n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# computing loss\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdensity_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/21cm-sbi/cl_models.py:126\u001b[0m, in \u001b[0;36mRNVP.loss\u001b[0;34m(self, x, cond)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mFloatTensor, cond: torch\u001b[38;5;241m.\u001b[39mFloatTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m--> 126\u001b[0m     z, jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum(z\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m jac\n\u001b[1;32m    128\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/FrEIA/framework/sequence_inn.py:106\u001b[0m, in \u001b[0;36mSequenceINN.forward\u001b[0;34m(self, x_or_z, c, rev, jac)\u001b[0m\n\u001b[1;32m    104\u001b[0m         x_or_z, j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_list[i](x_or_z, jac\u001b[38;5;241m=\u001b[39mjac, rev\u001b[38;5;241m=\u001b[39mrev)\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m         x_or_z, j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_or_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     log_det_jac \u001b[38;5;241m=\u001b[39m j \u001b[38;5;241m+\u001b[39m log_det_jac\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_or_z \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforce_tuple_output \u001b[38;5;28;01melse\u001b[39;00m x_or_z[\u001b[38;5;241m0\u001b[39m], log_det_jac\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/FrEIA/modules/all_in_one_block.py:248\u001b[0m, in \u001b[0;36mAllInOneBlock.forward\u001b[0;34m(self, x, c, rev, jac)\u001b[0m\n\u001b[1;32m    245\u001b[0m     x1c \u001b[38;5;241m=\u001b[39m x1\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rev:\n\u001b[0;32m--> 248\u001b[0m     a1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1c\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     x2, j2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affine(x2, a1)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/remote/gpu01a/schlenker/ml-venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "freezed_epochs = 5\n",
    "#train_test_data_ration = 0.9\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "optimizer_params = {\n",
    "    \"lr\": 9e-4,\n",
    "}\n",
    "\n",
    "'''model_de = RNVP(in_dim=6, n_blocks=6, n_nodes=128,\n",
    "               hidden_layer=1, batch_norm=True, device=device)\n",
    "\n",
    "model_de = testmodel(inference._neural_net)\n",
    "\n",
    "sbi = SBIHandler(density_estimator=model_de, summary_net=model_sn.Model, device=device)\n",
    "\n",
    "'''\n",
    "\n",
    "#rec_model = global_temp_smol_inv_super_smol(in_dim = 6)\n",
    "density_model = NPEHandler(RNVP, density_estimator_kwargs={\n",
    "    \"in_dim\" : 6, \n",
    "    \"n_blocks\" : 8,\n",
    "    \"n_nodes\" : 256,\n",
    "    \"hidden_layer\" : 1, \n",
    "    \"batch_norm\" : True}\n",
    "    , device=device)\n",
    "summary_net = SNHandler(Summary_net_lc_super_smol, device = device)\n",
    "summary_net.load(\"./\")\n",
    "\n",
    "sbi = Trainer(NetworkHandlerDE = density_model, NetworkHandlerSN = summary_net, \n",
    "              training_data=train_dataloader, test_data=test_dataloader,\n",
    "                device = device)\n",
    "\n",
    "sbi.train(config={\n",
    "    \"grad_clip\": 0,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"optimizer_kwargs\": optimizer_params,\n",
    "}, epochs=epochs, freezed_epochs=freezed_epochs)\n",
    "\n",
    "sbi.save_model(\"npe.pt\")\n",
    "\n",
    "ana = Analysis(sbi, test_dataloader, device)\n",
    "#ana.run_sensitivity_analysis(num_points=330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Succesfully initialized SNHandler\n",
      "/tmp/ipykernel_2286857/1642808413.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_sn.encoder.load_state_dict(torch.load(\"encoder.pt\", map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_2286857/1642808413.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_sn.decoder.load_state_dict(torch.load(\"decoder.pt\", map_location=torch.device('cpu')))\n",
      "INFO: Succesfully initialized NPEHandler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2286857/1642808413.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_de.density_estimator.load_state_dict(torch.load(\"density_model.ptdensity_model.pt\", map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6]) torch.Size([1, 6])\n",
      "logprob= tensor([[nan, nan, nan, nan, nan, nan]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/remote/gpu01a/schlenker/21cm-sbi/made_backbone.py:92: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  self.batch_var = x.var(0) # note MAF paper uses biased variance estimate; ie x.var(0, unbiased=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan, nan, nan, nan]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_sn = SNHandler(encoder=Summary_net_lc_super_smol, decoder=Summary_net_lc_super_smol_inv, device='cpu',)\n",
    "model_sn.encoder.load_state_dict(torch.load(\"encoder.pt\", map_location=torch.device('cpu')))\n",
    "model_sn.decoder.load_state_dict(torch.load(\"decoder.pt\", map_location=torch.device('cpu')))\n",
    "model_de = NPEHandler(density_estimator=MAF, \n",
    "                      density_estimator_kwargs={\n",
    "                        \"n_blocks\": 6,\n",
    "                        \"in_dim\": 6,\n",
    "                        \"hidden_layer\": 2,\n",
    "                        \"n_nodes\": 64,\n",
    "                        \"activation\": 'gelu',\n",
    "                    },\n",
    "                      device='cpu')\n",
    "model_de.density_estimator.load_state_dict(torch.load(\"density_model.ptdensity_model.pt\", map_location=torch.device('cpu')))\n",
    "\n",
    "trainer = Trainer(NetworkHandlerDE=model_de, NetworkHandlerSN=model_sn, test_data=test_dataloader,training_data=train_dataloader, device='cpu')\n",
    "\n",
    "i=2\n",
    "for lab, img, rng in test_dataloader:\n",
    "    plt.imshow(img[i][0][0])\n",
    "    plt.show()\n",
    "    \n",
    "    z = model_sn.encoder(img,rng)[i].unsqueeze(0)\n",
    "    print(z.shape, lab[i].unsqueeze(0).shape)\n",
    "    z = model_de.forward(z, lab[i].unsqueeze(0))\n",
    "    print(\"logprob=\", z[1])\n",
    "    rec = model_sn.decoder(z[0])\n",
    "    \n",
    "    print(z[0])\n",
    "    plt.imshow(rec[0][0][0].detach().numpy())\n",
    "    plt.show()\n",
    "    break\n",
    "  \n",
    "ana = Analysis(trainer, test_dataloader, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan]], grad_fn=<AddBackward0>),\n",
       " tensor([[nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_de.forward(torch.rand(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ana = Analysis(sbi, test_dataloader, device, path=\"./sbi_plots/test/\")\n",
    "ana.marginals()\n",
    "ana.run_sbc(2000)\n",
    "ana.check_latent_space(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opti search\n",
    "\n",
    "from hyperopt import hp\n",
    "search_space = {\n",
    "                #\"uniform\": tune.uniform(-5, -1),  # Uniform float between -5 and -1\n",
    "                #\"quniform\": tune.quniform(3.2, 5.4, 0.2),  # Round to multiples of 0.2\n",
    "                #\"loguniform\": tune.loguniform(1e-4, 1e-1),  # Uniform float in log space\n",
    "                #\"qloguniform\": tune.qloguniform(1e-4, 1e-1, 5e-5),  # Round to multiples of 0.00005\n",
    "                #\"randn\": tune.randn(10, 2),  # Normal distribution with mean 10 and sd 2\n",
    "                #\"qrandn\": tune.qrandn(10, 2, 0.2),  # Round to multiples of 0.2\n",
    "                #\"randint\": tune.randint(-9, 15),  # Random integer between -9 and 15\n",
    "                #\"qrandint\": tune.qrandint(-21, 12, 3),  # Round to multiples of 3 (includes 12)\n",
    "                #\"lograndint\": tune.lograndint(1, 10),  # Random integer in log space\n",
    "                #\"qlograndint\": tune.qlograndint(1, 10, 2),  # Round to multiples of 2\n",
    "                #\"choice\": tune.choice([\"a\", \"b\", \"c\"]),  # Choose one of these options uniformly\n",
    "                \"optimizer\": tune.choice([torch.optim.AdamW]),\n",
    "                \"optimizer_kwargs\" : {\n",
    "                    \"lr\" : tune.loguniform(1e-5, 1e-1),\n",
    "                    \"weight_decay\" : tune.loguniform(1e-5, 1e-1),\n",
    "                },\n",
    "                \"summary_network_kwargs\" : {\n",
    "                \"layer_per_block1\": tune.randint(1, 3),\n",
    "                \"layersize1\" : tune.randint(2, 128),\n",
    "                \"filter_size1\" : tune.choice([2, 3, 5, 7]),\n",
    "                \n",
    "                \"layer_per_block2\": tune.randint(1, 3),\n",
    "                \"layersize2\" : tune.randint(2, 128),\n",
    "                \"filter_size2\" : tune.choice([2, 3, 5, 7]),\n",
    "                \n",
    "                \"layer_per_block3\": tune.randint(1, 3),\n",
    "                \"layersize3\" : tune.randint(2, 128),\n",
    "                \"filter_size3\" : tune.choice([2, 3, 5, 7]),},\n",
    "                    \n",
    "}\n",
    "\n",
    "train_kwargs = {\"epochs\": 200,\n",
    "                \"training_data\": train_dataloader,\n",
    "                \"test_data\": test_dataloader,}\n",
    "\n",
    "model_sn = SNHandler(Summary_net_1dps, device = 'cuda', no_progress_bar=True)\n",
    "model_sn.opti_params(search_space=search_space, \n",
    "                train_kwargs=train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.rand(32,10,8)*torch.rand(32,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana = Analysis(sbi, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbi.de_net.sample(10, torch.rand(1,6).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ana.marginals()\n",
    "#ana.conditionals()\n",
    "sbi.de_net._device = device\n",
    "sbi.de_net.to(device)\n",
    "ana.run_sbc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'sensitivity_sum_net_image': tensor([0.0035, 0.0018, 0.0011, 0.0011, 0.0015, 0.0016, 0.0013, 0.0005, 0.0001],\n",
    "       device='cuda:0'), 'sensitivity_sum_net_range': tensor([0.0002, 0.0056], device='cuda:0')}\n",
    "torch.Size([10, 6])\n",
    "{'sensitivity_density_net_logprob': tensor([0.0952, 0.2920, 0.0810, 0.1007, 0.2179, 0.3954], device='cuda:0')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for lab, img, rnge in test_dataloader:\n",
    "        lab, img, rnge = lab.to(device), img.to(device), rnge.to(device)\n",
    "        img = sbi.summary_net(img, rnge)\n",
    "        for im in img:\n",
    "            img = im.unsqueeze(0)\n",
    "            samples = sbi.density_estimator.sample(1000, im)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, rnge = torch.rand(32,10,8).to(device), torch.rand(32,2).to(device)\n",
    "rnge.requires_grad = True\n",
    "x.requires_grad = True\n",
    "out = sbi.summary_net(x, rnge).cpu().mean(0).mean()\n",
    "out.backward()\n",
    "print(rnge.grad.mean(0))\n",
    "print(x.grad.mean(0).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [-1]\n",
    "data = torch.rand(32,10,8)\n",
    "if axis == [-1]:\n",
    "    axes_to_exclude = [data.dim() - 1]\n",
    "axes_to_reduce = [i for i in range(data.dim()) if i not in idx]\n",
    "print(torch.mean(data, dim=axes_to_reduce).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_to_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example input tensor with gradient tracking enabled\n",
    "input_tensor = torch.tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\n",
    "\n",
    "# Define a simple model or function for demonstration\n",
    "# Here we use a simple sum of squares as an example function\n",
    "output = input_tensor.pow(2).sum()\n",
    "\n",
    "# Perform backpropagation to calculate gradients\n",
    "output.backward()\n",
    "\n",
    "# The gradient (sensitivity) of the output with respect to the input\n",
    "sensitivity = input_tensor.grad\n",
    "print(\"Sensitivity:\\n\", sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tarp_refpoint(thetas: Tensor) -> Tensor:\n",
    "    \"\"\"Returns reference points for the TARP diagnostic, sampled from a uniform.\"\"\"\n",
    "\n",
    "    # obtain min/max per dimension of theta\n",
    "    lo = thetas.min(dim=0).values  # min for each theta dimension\n",
    "    hi = thetas.max(dim=0).values  # max for each theta dimension\n",
    "\n",
    "    refpdf = torch.distributions.Uniform(low=lo, high=hi)\n",
    "\n",
    "    # sample one reference point for each entry in theta\n",
    "    return refpdf.sample(torch.Size([thetas.shape[0]]))\n",
    "\n",
    "num_points, num_samples = 32,500\n",
    "\n",
    "# apply samplfunc with sumnet true here\n",
    "for lab, img, rnge in test_dataloader:\n",
    "    img, rnge = img.to(device), rnge.to(device)\n",
    "    img = sbi.summary_net(img, rnge).detach().cpu()\n",
    "    break\n",
    "    \n",
    "    \n",
    "for i in range(num_points):\n",
    "    sample = sbi.density_estimator.sample(num_samples=num_samples, x=img[i]).unsqueeze(1).detach().cpu()\n",
    "    if i == 0:\n",
    "        samples = sample\n",
    "    else:\n",
    "        samples = torch.cat([samples, sample], dim=1)\n",
    "del img, rnge\n",
    "        \n",
    "num_bins = 30\n",
    "\n",
    "if num_bins is None:\n",
    "    num_bins = num_samples // 10\n",
    "\n",
    "distance = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "reference = get_tarp_refpoint(lab)\n",
    "\n",
    "# distances between references and samples\n",
    "sample_dists = distance(reference, samples)\n",
    "\n",
    "# distances between references and true values\n",
    "theta_dists = distance(reference, lab)\n",
    "\n",
    "# compute coverage, f in algorithm 2\n",
    "coverage_values = (\n",
    "    torch.sum(sample_dists < theta_dists, dim=0) / num_samples\n",
    ")\n",
    "hist, alpha = torch.histogram(coverage_values, density=True, bins=num_bins)\n",
    "# calculate empirical CDF via cumsum and normalize\n",
    "ecp = torch.cumsum(hist, dim=0) / hist.sum()\n",
    "# add 0 to the beginning of the ecp curve to match the alpha grid\n",
    "ecp = torch.cat([Tensor([0]), ecp])\n",
    "\n",
    "# Similar to SBC, we can check then check whether the distribution of ecp is close to\n",
    "# that of alpha.\n",
    "atc, ks_pval = check_tarp(ecp, alpha)\n",
    "print(atc, \"Should be close to 0\")\n",
    "print(ks_pval, \"Should be larger than 0.05\")\n",
    "\n",
    "plot_tarp(ecp, alpha);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "sb.heatmap(blub.detach(), cmap='coolwarm', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'aug_'\n",
    "\n",
    "# rewrite rev_sample, the current implementation is really shitty\n",
    "sbi.run_sbc(Validation_Dataset = test_dataloader, plotname= name,)\n",
    "'''sampling_parameter={\n",
    "    'sample_with' :'mcmc',\n",
    "    'num_chains': 20,\n",
    "    \"method\": \"slice_np_vectorized\"})'''\n",
    "\n",
    "\n",
    "#noaug: tensor([8.7545e-05, 2.1467e-05, 1.9525e-05, 4.4741e-15, 5.4385e-06, 5.0802e-11])\n",
    "# aug: tensor([9.5508e-09, 1.0710e-13, 4.7865e-04, 1.3318e-08, 8.7801e-09, 5.4540e-06])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions.transforms as torch_tf\n",
    "from torch.optim.adam import Adam\n",
    "\n",
    "prior = utils.BoxUniform(low=torch.zeros((6)), high=torch.ones((6)), device=device)\n",
    "potential_fn = LikelihoodBasedPotential(sbi.density_estimator, prior, x_o=torch.rand(6, device=device), device=device)\n",
    "loss = potential_fn(torch.rand(6,6, device=device)).squeeze().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "potential_fn = potential_fn\n",
    "inits = prior.sample((100,))\n",
    "theta_transform = None\n",
    "num_iter = 1_000\n",
    "num_to_optimize = 5\n",
    "learning_rate = 0.01\n",
    "save_best_every = 10\n",
    "show_progress_bars = False\n",
    "interruption_note = \"\"\n",
    "\n",
    "if theta_transform is None:\n",
    "    theta_transform = torch_tf.IndependentTransform(\n",
    "        torch_tf.identity_transform, reinterpreted_batch_ndims=1\n",
    "    )\n",
    "else:\n",
    "    theta_transform = theta_transform\n",
    "\n",
    "init_probs = potential_fn(inits).detach()\n",
    "\n",
    "# Pick the `num_to_optimize` best init locations.\n",
    "sort_indices = torch.argsort(init_probs, dim=0)\n",
    "sorted_inits = inits[sort_indices]\n",
    "optimize_inits = sorted_inits[-num_to_optimize:]\n",
    "\n",
    "# The `_overall` variables store data accross the iterations, whereas the\n",
    "# `_iter` variables contain data exclusively extracted from the current\n",
    "# iteration.\n",
    "best_log_prob_iter = torch.max(init_probs)\n",
    "best_theta_iter = sorted_inits[-1]\n",
    "best_theta_overall = best_theta_iter.detach().clone()\n",
    "best_log_prob_overall = best_log_prob_iter.detach().clone()\n",
    "\n",
    "argmax_ = best_theta_overall\n",
    "max_val = best_log_prob_overall\n",
    "\n",
    "optimize_inits = theta_transform(optimize_inits)\n",
    "optimize_inits.requires_grad_(True)  # type: ignore\n",
    "optimizer = Adam([optimize_inits], lr=learning_rate)  # type: ignore\n",
    "\n",
    "iter_ = 0\n",
    "\n",
    "# Try-except block in case the user interrupts the program and wants to fall\n",
    "# back on the last saved `.map_`. We want to avoid a long error-message here.\n",
    "\n",
    "while iter_ < num_iter:\n",
    "    optimizer.zero_grad()\n",
    "    probs = potential_fn(theta_transform.inv(optimize_inits)).squeeze()\n",
    "    print(optimize_inits)\n",
    "    print(probs)\n",
    "    loss = probs.sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if iter_ % save_best_every == 0 or iter_ == num_iter - 1:\n",
    "            # Evaluate the optimized locations and pick the best one.\n",
    "            log_probs_of_optimized = potential_fn(\n",
    "                theta_transform.inv(optimize_inits)\n",
    "            )\n",
    "            best_theta_iter = optimize_inits[  # type: ignore\n",
    "                torch.argmax(log_probs_of_optimized)\n",
    "            ].view(1, -1)\n",
    "            best_log_prob_iter = potential_fn(\n",
    "                theta_transform.inv(best_theta_iter)\n",
    "            )\n",
    "            if best_log_prob_iter > best_log_prob_overall:\n",
    "                best_theta_overall = best_theta_iter.detach().clone()\n",
    "                best_log_prob_overall = best_log_prob_iter.detach().clone()\n",
    "\n",
    "        if show_progress_bars:\n",
    "            print(\n",
    "                \"\\r\",\n",
    "                f\"Optimizing MAP estimate. Iterations: {iter_ + 1} / \"\n",
    "                f\"{num_iter}. Performance in iteration \"\n",
    "                f\"{divmod(iter_ + 1, save_best_every)[0] * save_best_every}: \"\n",
    "                f\"{best_log_prob_iter.item():.2f} (= unnormalized log-prob)\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        argmax_ = theta_transform.inv(best_theta_overall)\n",
    "        max_val = best_log_prob_overall\n",
    "\n",
    "    iter_ += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_attr = {\n",
    "        \"sample_with\": \"mcmc\", \n",
    "        \"mcmc_method\": \"slice_np_vectorized\",\n",
    "        \"warmup_steps\": 200,\n",
    "        \"num_chains\": 16, # change \n",
    "        \"init_strategy\": \"proposal\", # try 'sir' here\n",
    "        \"num_workers\": 4,\n",
    "}\n",
    "print(type(sample_attr))\n",
    "blub = sample_attr.pop('sample_with')\n",
    "print(blub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbi\n",
    "with torch.no_grad():\n",
    "    for i, (lab, img,_) in enumerate(test_dataloader):\n",
    "        img, lab = img.to(device), lab.to(device)\n",
    "        \n",
    "        if not i:\n",
    "            summary_vec = torch.empty(0,lab.shape[1], device=device)\n",
    "            labels = torch.empty(0,lab.shape[1], device=device)\n",
    "\n",
    "        pred = sbi.summary_net(img)\n",
    "        summary_vec = torch.cat((summary_vec, pred), dim=0)\n",
    "        labels = torch.cat((labels, lab), dim=0)\n",
    "\n",
    "num_samples = 10000\n",
    "rank_inn = torch.empty(summary_vec.shape)\n",
    "dap_samples = torch.empty((summary_vec.shape[0], summary_vec.shape[1]))\n",
    "# sbc rank stat\n",
    "with alive_bar(summary_vec.shape[0], force_tty=True, refresh_secs=1) as bar:\n",
    "    for i in range(summary_vec.shape[0]):\n",
    "        samples = sbi.density_estimator.sample(x = summary_vec[i].unsqueeze(0), num_samples=num_samples,\n",
    "                                                 enable_transform=False,\n",
    "                                           sample_with='mcmc', mcmc_method=\"slice_np_vectorized\")\n",
    "        samples = samples.detach()\n",
    "        dap_samples[i] = samples[0]\n",
    "        for j in range(summary_vec.shape[1]):\n",
    "            rank_inn[i,j] = (samples[:,j]<labels[i,j]).sum().item()\n",
    "        bar()\n",
    "        \n",
    "'''rank_maf = torch.empty(summary_vec.shape)\n",
    "# sbc rank stat\n",
    "with alive_bar(summary_vec.shape[0], force_tty=True, refresh_secs=1) as bar:\n",
    "    for i in range(summary_vec.shape[0]):\n",
    "        samples = posterior.posterior_estimator.sample((10000,), summary_vec[i].unsqueeze(0))[:,0,:]\n",
    "        samples = samples.detach()\n",
    "        dap_samples[i] = samples[0]\n",
    "        for j in range(summary_vec.shape[1]):\n",
    "            rank_maf[i,j] = (samples[:,j]<labels[i,j]).sum().item()\n",
    "        bar()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for i, (lab, img,_) in enumerate(test_dataloader):\n",
    "        img, lab = img.to(device), lab.to(device)\n",
    "        \n",
    "        if not i:\n",
    "            summary_vec = torch.empty(0,lab.shape[1], device=device)\n",
    "            labels = torch.empty(0,lab.shape[1], device=device)\n",
    "\n",
    "        pred = sbi.summary_net(img)\n",
    "        summary_vec = torch.cat((summary_vec, pred), dim=0)\n",
    "        labels = torch.cat((labels, lab), dim=0)\n",
    "\n",
    "num_samples = 10000\n",
    "rank_inn = torch.empty(summary_vec.shape)\n",
    "dap_samples = torch.empty((summary_vec.shape[0], summary_vec.shape[1]))\n",
    "# sbc rank stat\n",
    "with alive_bar(summary_vec.shape[0], force_tty=True, refresh_secs=1) as bar:\n",
    "    for i in range(summary_vec.shape[0]):\n",
    "        samples = sbi.density_estimator.sample(x = summary_vec[i].unsqueeze(0), num_samples=num_samples,\n",
    "                                                 enable_transform=False,\n",
    "                                           sample_with='mcmc', mcmc_method=\"slice_np_vectorized\")\n",
    "        samples = samples.detach()\n",
    "        dap_samples[i] = samples[0]\n",
    "        for j in range(summary_vec.shape[1]):\n",
    "            rank_inn[i,j] = (samples[:,j]<labels[i,j]).sum().item()\n",
    "        bar()\n",
    "        \n",
    "'''rank_maf = torch.empty(summary_vec.shape)\n",
    "# sbc rank stat\n",
    "with alive_bar(summary_vec.shape[0], force_tty=True, refresh_secs=1) as bar:\n",
    "    for i in range(summary_vec.shape[0]):\n",
    "        samples = posterior.posterior_estimator.sample((10000,), summary_vec[i].unsqueeze(0))[:,0,:]\n",
    "        samples = samples.detach()\n",
    "        dap_samples[i] = samples[0]\n",
    "        for j in range(summary_vec.shape[1]):\n",
    "            rank_maf[i,j] = (samples[:,j]<labels[i,j]).sum().item()\n",
    "        bar()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(samples[:,0].detach().cpu(), range=(-5,5), bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    lab, img, _ = test_dataloader.dataset[i+2]\n",
    "\n",
    "    lab, img = lab.to(device), img.to(device)\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    summary = sbi.summary_net(img).detach()\n",
    "    cond_size = summary.shape[-1]\n",
    "    summaryn = summary.repeat(5,1)\n",
    "    labn = torch.cat([lab.unsqueeze(0), torch.rand(4,6, device=device)], dim=0)\n",
    "    log_prob = sbi.density_estimator.log_prob(summaryn, labn)\n",
    "    print(- (logp.sum(-1) + sbi.density_estimator.base_dist.log_prob(samples).sum(-1)))\n",
    "    print(log_prob.shape)\n",
    "    print(lab)\n",
    "    print(density_net.log_prob(summaryn.unsqueeze(0),labn).shape)\n",
    "    break\n",
    "utils.BoxUniform(low=torch.zeros(6), high=torch.ones(6), device=device).log_prob(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-density_net.log_prob(labn.unsqueeze(0), summaryn))\n",
    "s, p = sbi.density_estimator.forward(summaryn, labn)\n",
    "p = p.sum(-1) + sbi.density_estimator.base_dist.log_prob(s).sum(-1)\n",
    "print(-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryn = summary.squeeze(0)\n",
    "labn = labn\n",
    "print(summaryn.shape, labn.shape)\n",
    "density_net.log_prob(labn, summaryn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "sbi.density_estimator.net.to(device)\n",
    "sbi.device = device\n",
    "prior = utils.BoxUniform(low=torch.zeros(6), high=torch.ones(6), device=device)\n",
    "potential_fn = LikelihoodBasedPotential(sbi.density_estimator, prior, x_o=None, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_fn.set_x(torch.rand(1,6, device=device))\n",
    "print(potential_fn(torch.rand(10,6, device=device)))\n",
    "\n",
    "posterior = MCMCPosterior(\n",
    "    potential_fn=potential_fn, proposal=prior\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.BoxUniform(low=torch.zeros(6), high=torch.ones(6), device=device).log_prob(torch.rand(10,6, device='cuda')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab, x, _ in test_dataloader:\n",
    "    break\n",
    "\n",
    "batch_size=1\n",
    "batch_size_prior = 32\n",
    "x = sbi.summary_net.to('cpu')(x)[0].unsqueeze(0)\n",
    "sbi.density_estimator.to('cpu')\n",
    "sbi.device = 'cpu'\n",
    "theta_prior = torch.rand(32, 6)\n",
    "repeated_x =  repeat_rows(x, 11)\n",
    "lab = lab[0].unsqueeze(0)\n",
    "probs = torch.cat(\n",
    "        [(1 - torch.eye(batch_size)), torch.ones(batch_size, batch_size_prior)], dim=-1\n",
    "        ) / (batch_size + batch_size_prior - 1)\n",
    "choices = torch.multinomial(probs, num_samples=10, replacement=False)\n",
    "\n",
    "contrasting_theta = torch.cat([lab, theta_prior], dim=0)[choices]\n",
    "atomic_theta = torch.cat((lab[:, None, :], contrasting_theta), dim=1).reshape(\n",
    "    batch_size * (11), -1\n",
    ")\n",
    "res = sbi.density_estimator.forward(atomic_theta, repeated_x).reshape(\n",
    "            batch_size, 10 + 1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import distributions as D\n",
    "D.Uniform(0,1).sample((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributions.Uniform(0,1).sample((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbi.density_estimator.base_dist.sample((10000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''prior = (lambda x: x)\n",
    "sbi = SBIHandler(density_estimator=model_de, summary_net=model_sn.Model, device=device)\n",
    "sbi.load_model()'''\n",
    "\n",
    "lab, img, _ = test_dataloader.dataset[3]\n",
    "\n",
    "lab, img = lab.to(device), img.to(device)\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "summary = sbi.summary_net(img)\n",
    "\n",
    "samples, _ = sbi.density_estimator.sample(10000, summary)\n",
    "print(samples.shape)\n",
    "# plot posterior samples\n",
    "figure, axis = analysis.pairplot(samples = samples.detach().to('cpu').numpy(), points=lab.detach().to('cpu').numpy(),\n",
    "       limits=[[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],], figsize=(10, 10),\n",
    "       labels = [r\"$M_{WDM}$\", r\"$\\Omega_m$\", r\"$L_X$\", r\"$E_0$\", r\"$T_{vir, ion}$\", r\"$\\zeta$\"],\n",
    "       #quantiles=((0.16, 0.84, 0.0015, 0.99815)), levels=(1 - np.exp(-0.5),1 - np.exp(-9/2)),\n",
    "       upper = 'hist', lower = 'contour', diag = 'kde')\n",
    "figure.savefig(\"inn_40.png\", dpi=300)\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(posterior.posterior_estimator.sample((1000,), summary_vec[0].unsqueeze(0))[:,0,0].detach().cpu().numpy(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SNPE ###\n",
    "\n",
    "from sbi.utils.get_nn_models import (\n",
    "    posterior_nn,\n",
    ")  # For SNPE: posterior_nn(), SNLE: likelihood_nn(). For SNRE: classifier_nn()\n",
    "from sbi.inference import SNPE\n",
    "from sbi import utils, analysis\n",
    "from sbi.utils import RestrictedPrior, get_density_thresholder\n",
    "\n",
    "# load the summary model\n",
    "model = SumnetHandler(Model = Summary_net_lc_super_smol, device=device)\n",
    "model.load(\"./summary_net.pt\")\n",
    "\n",
    "prior = utils.BoxUniform(low=torch.zeros((6)), high=torch.ones((6)), device=device)\n",
    "\n",
    "# define the maf\n",
    "density_estimator_build_fun = posterior_nn(\n",
    "    model=\"maf\", hidden_features=128, num_transforms=6, z_score_theta='none',\n",
    "    z_score_x='none', batch_norm=True\n",
    ")\n",
    "\n",
    "# train the maf\n",
    "inference = SNPE(prior=prior, density_estimator=density_estimator_build_fun, device=device)\n",
    "\n",
    "y,x,idx = train_dataloader.dataset()\n",
    "\n",
    "inference.append_simulations(y,y)\n",
    "\n",
    "inference.train_indices = [0]\n",
    "\n",
    "\n",
    "density_net, summary_net, statistics = inference.train(train_dataloader=train_dataloader,\n",
    "                                    test_dataloader=test_dataloader,\n",
    "                                    optimizer=optimizer,\n",
    "                                    optimizer_parameter=optimizer_params,\n",
    "                                    summary_net=model.Model,\n",
    "                                    train_summary_net_freezed_rounds=99,\n",
    "                                    stop_after_epochs=99,\n",
    "                                    max_num_epochs=20,\n",
    "                                    clip_max_norm=None)\n",
    "\n",
    "# sample the posterior using the first 3 parameters from the testset\n",
    "posterior = inference.build_posterior(density_net, prior=prior)\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    lab, img, _ = test_dataloader.dataset[i]\n",
    "\n",
    "    lab, img = lab.to(device), img.to(device)\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    summary = sbi.summary_net(img).detach()\n",
    "    cond_size = summary.shape[-1]\n",
    "    nsamples = 1000\n",
    "    samples = posterior.sample(nsamples, summary)\n",
    "    # plot posterior samples\n",
    "    figure, axis = analysis.pairplot(samples = samples.detach().to('cpu').numpy(), points=lab.detach().to('cpu').numpy(),\n",
    "        limits=[[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],], figsize=(10, 10),\n",
    "        labels = [r\"$M_{WDM}$\", r\"$\\Omega_m$\", r\"$L_X$\", r\"$E_0$\", r\"$T_{vir, ion}$\", r\"$\\zeta$\"],\n",
    "        #quantiles=((0.16, 0.84, 0.0015, 0.99815)), levels=(1 - np.exp(-0.5),1 - np.exp(-9/2)),\n",
    "        upper = 'hist', lower = 'contour', diag = 'kde')\n",
    "    if save: figure.savefig(f\"maf_theirs_{i}.png\", dpi=300)\n",
    "    figure.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    lab, img, _ = test_dataloader.dataset[i]\n",
    "\n",
    "    lab, img = lab.to(device), img.to(device)\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    summary = sbi.summary_net(img).detach()\n",
    "    cond_size = summary.shape[-1]\n",
    "    nsamples = 1000\n",
    "    samples = posterior.sample((nsamples,), summary)\n",
    "    # plot posterior samples\n",
    "    figure, axis = analysis.pairplot(samples = samples.detach().to('cpu').numpy(), points=lab.detach().to('cpu').numpy(),\n",
    "        limits=[[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],], figsize=(10, 10),\n",
    "        labels = [r\"$M_{WDM}$\", r\"$\\Omega_m$\", r\"$L_X$\", r\"$E_0$\", r\"$T_{vir, ion}$\", r\"$\\zeta$\"],\n",
    "        #quantiles=((0.16, 0.84, 0.0015, 0.99815)), levels=(1 - np.exp(-0.5),1 - np.exp(-9/2)),\n",
    "        upper = 'hist', lower = 'contour', diag = 'kde')\n",
    "    if save: figure.savefig(f\"maf_theirs_{i}.png\", dpi=300)\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SNPE - backup ###\n",
    "\n",
    "from sbi.utils.get_nn_models import (\n",
    "    posterior_nn,\n",
    ")  # For SNPE: posterior_nn(), SNLE: likelihood_nn(). For SNRE: classifier_nn()\n",
    "from sbi.inference import SNPE, SNLE\n",
    "from sbi import utils, analysis\n",
    "\n",
    "# load the summary model\n",
    "model = ModelHandler(Model = Summary_net_lc_super_smol, device=device)\n",
    "model.load_model(\"./summary_net.pt\")\n",
    "\n",
    "prior = utils.BoxUniform(low=torch.zeros((6)), high=torch.ones((6)), device=device)\n",
    "\n",
    "# define the maf\n",
    "density_estimator_build_fun = posterior_nn(\n",
    "    model=\"maf\", hidden_features=60, num_transforms=6, z_score_theta='none',\n",
    "    z_score_x='none', \n",
    ")\n",
    "\n",
    "# train the maf\n",
    "inference = SNPE(prior=prior, density_estimator=density_estimator_build_fun, device=device)\n",
    "\n",
    "y,x,idx = train_dataloader.dataset()\n",
    "\n",
    "inference.append_simulations(y,y)\n",
    "\n",
    "inference.train_indices = [0]\n",
    "\n",
    "\n",
    "density_net, summary_net, statistics = inference.train(train_dataloader=train_dataloader,\n",
    "                                    test_dataloader=test_dataloader,\n",
    "                                    optimizer=optimizer,\n",
    "                                    optimizer_parameter=optimizer_params,\n",
    "                                    summary_net=model.Model,\n",
    "                                    train_summary_net_freezed_rounds=5,\n",
    "                                    stop_after_epochs=20,\n",
    "                                    max_num_epochs=20,\n",
    "                                    clip_max_norm=None)\n",
    "\n",
    "# sample the posterior using the first 3 parameters from the testset\n",
    "posterior = inference.build_posterior(density_net, prior=prior)\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    #idx = np.random.randint(0,x.shape[0])\n",
    "    idx = i\n",
    "    y,x,_ = test_dataloader.dataset.__getitem__(i)\n",
    "    y,x = y.unsqueeze(0), x.unsqueeze(0)\n",
    "    print(y.shape, x.shape)\n",
    "\n",
    "    x = x.to(device)\n",
    "    \n",
    "    x = summary_net(x)\n",
    "\n",
    "    posterior_samples = posterior.sample((10000,), x=x).to('cpu')\n",
    "\n",
    "    # plot posterior samples\n",
    "    fig, ax = analysis.pairplot(\n",
    "        posterior_samples, limits=[[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],], figsize=(5, 5),\n",
    "        labels = [\"M_WDM\", \"OMm\", \"L_X\", \"NU_X_THRESH\", \"ION_Tvir_MIN\", \"HII_EFF_FACTOR\"],\n",
    "        points= y\n",
    "\n",
    "    )\n",
    "    \n",
    "    #fig.savefig(f\"./NPE_{i}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = inference.build_posterior(density_net, prior=prior)\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    #idx = np.random.randint(0,x.shape[0])\n",
    "    idx = i\n",
    "    y,x,_ = test_dataloader.dataset.__getitem__(i)\n",
    "    y,x = y.unsqueeze(0), x.unsqueeze(0)\n",
    "    print(y.shape, x.shape)\n",
    "\n",
    "    x = x.to(device)\n",
    "    \n",
    "    x = summary_net(x)\n",
    "\n",
    "    posterior_samples = posterior.sample((10000,), x=x).to('cpu')\n",
    "\n",
    "    # plot posterior samples\n",
    "    fig, ax = analysis.pairplot(\n",
    "        posterior_samples, limits=[[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],], figsize=(5, 5),\n",
    "        labels = [\"M_WDM\", \"OMm\", \"L_X\", \"NU_X_THRESH\", \"ION_Tvir_MIN\", \"HII_EFF_FACTOR\"],\n",
    "        points= y\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    y,x,_ = test_dataloader.dataset.__getitem__(i)\n",
    "    y,x = y.unsqueeze(0), x.unsqueeze(0)\n",
    "\n",
    "    x = x.to(device)\n",
    "\n",
    "    x = model.Model(x).detach()\n",
    "    sample, prob = density_net.sample_and_log_prob(sample_shape=torch.tensor([1]), condition=x.to('cuda'))\n",
    "    print(\"summary-vec = \", x)\n",
    "    print(\"true-vec = \", y)\n",
    "    print(\"sample-vec = \", sample.detach())\n",
    "    print(\"prob = \", prob.item())\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unsqueeze(train_dataloader.dataset.__getitem__(0)[1],0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"delete.me\", \"wb\") as handle:\n",
    "    pickle.dump(density_net, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_summary_net, train_loss_density_net, test_loss_summary_net, test_loss_density_net = statistics\n",
    "plt.plot(train_loss_summary_net, label=r'$\\log \\mathcal{L}_{\\Phi_{train}}$')\n",
    "plt.plot(np.asarray(train_loss_density_net)/32, label=r'$\\log \\mathcal{L}_{\\varphi_{train}}$')   \n",
    "plt.plot(test_loss_summary_net, label=r'$\\log \\mathcal{L}_{\\Phi_{test}}$')\n",
    "plt.plot(np.asarray(test_loss_density_net)/32, label=r'$\\log \\mathcal{L}_{\\varphi_{test}}$')\n",
    "plt.vlines(9, 0.5, 0, color='b', label='joint learning', colors='black')\n",
    "plt.legend()\n",
    "#plt.savefig(\"NPE_nsf_joint_loss.png\", dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NRE ###\n",
    "\n",
    "\n",
    "\n",
    "from sbi.utils.get_nn_models import (\n",
    "    likelihood_nn\n",
    ")  # For SNPE: posterior_nn(), SNLE: likelihood_nn(). For SNRE: classifier_nn()\n",
    "from sbi.inference import SNLE\n",
    "from sbi import utils, analysis\n",
    "\n",
    "# load the summary model\n",
    "model = SumnetHandler(Model = Summary_net_lc_super_smol, device=device)\n",
    "model.load(\"./summary_net.pt\")\n",
    "\n",
    "prior = utils.BoxUniform(low=torch.zeros((6)), high=torch.ones((6)), device=device)\n",
    "\n",
    "# define the maf\n",
    "ratio_estimator = (lambda x,y: NSF_AR(in_dim=6, n_blocks=2, n_nodes=64, reversed=True,\n",
    "               hidden_layer=1, batch_norm=True, device=device))\n",
    "\n",
    "ratio_estimator = likelihood_nn(\n",
    "    model = 'nsf', z_score_x='none',  z_score_theta='none', \n",
    "    hidden_features=64, num_blocks=3, use_batch_norm=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# train the maf\n",
    "inference = SNLE(prior=prior, device=device, density_estimator=ratio_estimator)\n",
    "\n",
    "y,x,idx = train_dataloader.dataset()\n",
    "\n",
    "inference.append_simulations(y,y)\n",
    "\n",
    "inference.train_indices = [0]\n",
    "\n",
    "density_net, summary_net, statistics = inference.train(train_dataloader=train_dataloader,\n",
    "                                    test_dataloader=test_dataloader,\n",
    "                                    optimizer=optimizer,\n",
    "                                    optimizer_parameter=optimizer_params,\n",
    "                                    summary_net=model.Model,\n",
    "                                    train_summary_net_freezed_rounds=50,\n",
    "                                    stop_after_epochs=20,\n",
    "                                    max_num_epochs=0,\n",
    "                                    clip_max_norm=None)\n",
    "\n",
    "# sample the posterior using the first 3 parameters from the testset\n",
    "posterior = inference.build_posterior(density_net, prior=prior)\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    #idx = np.random.randint(0,x.shape[0])\n",
    "    idx = i\n",
    "    y,x,_ = test_dataloader.dataset.__getitem__(i)\n",
    "    y,x = y.unsqueeze(0), x.unsqueeze(0)\n",
    "    print(y.shape, x.shape)\n",
    "\n",
    "    x = x.to(device)\n",
    "    \n",
    "    x = summary_net(x)\n",
    "\n",
    "    posterior_samples = posterior.sample((1000,), x=x, num_chains=5, mcmc_method='slice_np_vectorized').to('cpu')\n",
    "\n",
    "    # plot posterior samples\n",
    "    fig, ax = analysis.pairplot(\n",
    "        posterior_samples, limits=[[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],], figsize=(5, 5),\n",
    "        labels = [\"M_WDM\", \"OMm\", \"L_X\", \"NU_X_THRESH\", \"ION_Tvir_MIN\", \"HII_EFF_FACTOR\"],\n",
    "        points= y\n",
    "\n",
    "    )\n",
    "    \n",
    "    fig.savefig(f\"./NRE_{i}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference.potentials.likelihood_based_potential import likelihood_estimator_based_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot = LikelihoodBasedPotential(density_net, prior=prior, x_o=None, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot.set_x(torch.rand(1,6, device='cuda'))\n",
    "pot(torch.rand(10,6,device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import SNRE_C as SNRE\n",
    "ratio_estimator = (lambda x,y: ResNet(in_dim=6, n_blocks=2, n_nodes=64,\n",
    "               hidden_layer=2, batch_norm=True, device=device))\n",
    "\n",
    "prior = utils.BoxUniform(low=torch.zeros((6)), high=torch.ones((6)), device=device)\n",
    "\n",
    "'''ratio_estimator = classifier_nn(\n",
    "    model = 'resnet', z_score_x='none',  z_score_theta='none', \n",
    "    hidden_features=64, num_blocks=2, use_batch_norm=True\n",
    ")'''\n",
    "\n",
    "# train the maf\n",
    "inference = SNLE(prior=prior, device=device, density_estimator=ratio_estimator)\n",
    "\n",
    "# sample the posterior using the first 3 parameters from the testset\n",
    "posterior = inference.build_posterior(density_net, prior=prior)\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    #idx = np.random.randint(0,x.shape[0])\n",
    "    idx = i\n",
    "    y,x,_ = test_dataloader.dataset.__getitem__(i)\n",
    "    y,x = y.unsqueeze(0), x.unsqueeze(0)\n",
    "    print(y.shape, x.shape)\n",
    "\n",
    "    x = x.to(device)\n",
    "    \n",
    "    x = summary_net(x)\n",
    "\n",
    "    posterior_samples = posterior.sample((1000,), x=x, num_chains=20, mcmc_method='slice_np_vectorized').to('cpu')\n",
    "\n",
    "    # plot posterior samples\n",
    "    figure, axis = pairplot(samples = posterior_samples.cpu().numpy(), points=y.cpu().numpy(),\n",
    "        limits=[[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],], figsize=(10, 10),\n",
    "        labels = [r\"$M_{WDM}$\", r\"$\\Omega_m$\", r\"$L_X$\", r\"$E_0$\", r\"$T_{vir, ion}$\", r\"$\\zeta$\"],\n",
    "        #quantiles=((0.16, 0.84, 0.0015, 0.99815)), levels=(1 - np.exp(-0.5),1 - np.exp(-9/2)),\n",
    "        upper = 'hist', lower = 'contour', diag = 'kde')\n",
    "    if save: figure.savefig(f\"nre_{i}_old.png\", dpi=300)\n",
    "    figure.show()\n",
    "    \n",
    "    fig.savefig(f\"./NRE_{i}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(statistics)[1])\n",
    "plt.plot(np.asarray(statistics)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.diagnostics import check_sbc, run_sbc\n",
    "from sbi.analysis import sbc_rank_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.utils.torchutils import repeat_rows\n",
    "from torch import eye, ones\n",
    "num_atoms=10\n",
    "\n",
    "y,x,_ = test_dataloader.dataset.__getitem__(0)\n",
    "y,x = y.unsqueeze(0), x.unsqueeze(0)\n",
    "print(y.shape, x.shape)\n",
    "x = model.Model(x)\n",
    "\n",
    "y1, x1,_ = test_dataloader.dataset.__getitem__(1)\n",
    "y1,x1 = y1.unsqueeze(0), x1.unsqueeze(0)\n",
    "x1 = model.Model(x1)\n",
    "\n",
    "y, x = torch.cat((y,y1)), torch.cat((x,x1))\n",
    "\n",
    "batch_size = y.shape[0]\n",
    "print(f'{batch_size=}')\n",
    "\n",
    "repeated_x = repeat_rows(x, num_atoms)\n",
    "print(f'{repeated_x=}')\n",
    "\n",
    "# Choose `1` or `num_atoms - 1` thetas from the rest of the batch for each x.\n",
    "probs = ones(batch_size, batch_size) * (1 - eye(batch_size)) / (batch_size - 1)\n",
    "print(f'{probs=}')\n",
    "\n",
    "choices = torch.multinomial(probs, num_samples=num_atoms - 1, replacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train\n",
    "model.train(\n",
    "    epochs=epochs,\n",
    "    optimizer=optimizer(\n",
    "        model.Model.parameters(),\n",
    "        **optimizer_params),\n",
    "        lossf=loss(**loss_params))\n",
    "\n",
    "# test\n",
    "model.test(Validation_data = test_dataloader, Model = model.Model, lossf=loss(**loss_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take closer look at test\n",
    "ModelHandler.test_specific(test_dataloader, model.Model, loss(**loss_params), 1, denormalize=test_data.denormalize)\n",
    "\n",
    "# save the model\n",
    "#model.save_model(name = \"summary_net.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import SNPE, SNLE\n",
    "from sbi import utils, analysis\n",
    "\n",
    "# define model hyperparemeter\n",
    "user_params = {\n",
    "\"HII_DIM\": 40,\n",
    "\"BOX_LEN\": 160,\n",
    "\"N_THREADS\": 2,\n",
    "\"USE_INTERPOLATION_TABLES\": True,\n",
    "\"PERTURB_ON_HIGH_RES\": True\n",
    "}\n",
    "\n",
    "flag_options = {\n",
    "\"INHOMO_RECO\": True,\n",
    "\"USE_TS_FLUCT\": True\n",
    "}\n",
    "\n",
    "#simparams = p21c.outputs.LightCone.read(\"./data/run_36690\")\n",
    "# load the simulator class\n",
    "Leaf_simulator = Leaf(debug=True, user_params=user_params, flag_options=flag_options, redshift = 5.5)\n",
    "\n",
    "# define the prior ranges (only need for denormalization!)\n",
    "prior_range = torch.tensor([\n",
    "            [0.3,10.0], # M_WDM\n",
    "            [0.2,0.4], # OMm\n",
    "            [38, 42], # L_X\n",
    "            [100, 1500], # NU_X_THRESH\n",
    "            [4, 5.3], # ION_Tvir_MIN\n",
    "            [10.0, 250.0], # HII_EFF_FACTOR\n",
    "], dtype = torch.float32)\n",
    "\n",
    "# define the prior (uniform prior in this case)\n",
    "prior = utils.BoxUniform(low=torch.zeros((6)), high=torch.ones((6)))\n",
    "\n",
    "\n",
    "'''# define the simulator\n",
    "def simulation(theta):\n",
    "    M_WDM, OMm, L_X, NU_X_THRESH, ION_Tvir_MIN, HII_EFF_FACTOR = theta\n",
    "    cosmo_params = {\n",
    "        \"OMm\": OMm.item()\n",
    "        }\n",
    "    astro_params = {\n",
    "        \"L_X\": L_X.item(),\n",
    "        \"NU_X_THRESH\": NU_X_THRESH.item(),\n",
    "        \"ION_Tvir_MIN\": ION_Tvir_MIN.item(),\n",
    "        \"HII_EFF_FACTOR\": HII_EFF_FACTOR.item(),\n",
    "        \"INHOMO_RECO\": True\n",
    "    }\n",
    "    global_params = {\n",
    "        \"M_WDM\": M_WDM.item()\n",
    "    }\n",
    "\n",
    "\n",
    "    return Model.fast_forward(torch.as_tensor(Leaf_simulator.run_lightcone(\n",
    "        save = False, sanity_check = True, filter_peculiar = False, debug=False,\n",
    "        astro_params = astro_params, global_params = global_params, cosmo_params = cosmo_params).brightness_temp, dtype=torch.float32))\n",
    "\n",
    "\n",
    "def simulator(theta: torch.FloatTensor, Model: object, threads: int = 1):\n",
    "    tshape = theta.shape\n",
    "    schwimmhalle = Pool(max_workers=threads, max_tasks_per_child=1, mp_context=get_context('spawn'))\n",
    "    runner = [params for params in theta]\n",
    "    result = []\n",
    "    with alive_bar(len(runner), force_tty=True) as bar: \n",
    "        with schwimmhalle as p:\n",
    "            data = p.map(simulation, runner)\n",
    "            for dat in data:\n",
    "                lc_bt = future.result()\n",
    "\n",
    "                dat.add_done_callback(bar())\n",
    "    return data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if simulator is working\n",
    "#prepare_for_sbi(prior = prior, simulator = simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define point of interest\n",
    "# [M_WDM, OMm, L_X, NU_X_THRESH, ION_Tvir_MIN, HII_EFF_FACTOR]\n",
    "x_o = torch.tensor([2, 0.30964144154550644, 40.0, 500.0, 4.69897, 30.0], dtype=torch.float32)\n",
    "\n",
    "# A PPC is performed after we trained or neural posterior\n",
    "posterior.set_default_x(x_o)\n",
    "\n",
    "# We draw theta samples from the posterior. This part is not in the scope of SBI\n",
    "if __name__ == '__main__':\n",
    "    posterior_samples = posterior.sample((5000,))\n",
    "\n",
    "# We use posterior theta samples to generate x data\n",
    "    x_pp = torch.as_tensor(simulator(theta = posterior_samples, Model = model, threads=6))\n",
    "\n",
    "# We verify if the observed data falls within the support of the generated data\n",
    "_ = analysis.pairplot(\n",
    "    samples=x_pp,\n",
    "    points=x_o\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SNLE ###\n",
    "\n",
    "from sbi.utils.get_nn_models import (\n",
    "    likelihood_nn,\n",
    ")  \n",
    "\n",
    "# load the summary model\n",
    "model = ModelHandler(Model = Summary_net_lc_smol, device='cpu')\n",
    "model.load_model(\"./summary_net.pt\")\n",
    "\n",
    "# define the maf\n",
    "density_estimator_build_fun = posterior_nn(\n",
    "    model=\"maf\", hidden_features=60, num_transforms=6\n",
    ")\n",
    "\n",
    "# do inference using a freezed summary model\n",
    "x,y = model.full_inference(train_dataloader)\n",
    "\n",
    "# train the maf\n",
    "inference = SNLE(prior=prior, density_estimator=density_estimator_build_fun)\n",
    "inference.append_simulations(y,x)\n",
    "density_estimator = inference.train()\n",
    "# infere test data\n",
    "x,y = model.full_inference(test_dataloader)\n",
    "\n",
    "# sample the posterior using the first 3 parameters from the testset\n",
    "posterior = inference.build_posterior(density_estimator, prior=prior)\n",
    "for i in range(3):\n",
    "    \n",
    "    #idx = np.random.randint(0,x.shape[0])\n",
    "    idx = i\n",
    "    posterior_samples = posterior.sample((10000,), x=x[idx,:], num_workers=10, method=\"slice_np_vectorized\", num_chains=10)\n",
    "\n",
    "    # plot posterior samples\n",
    "    fig, ax = analysis.pairplot(\n",
    "        posterior_samples, limits=[[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],], figsize=(5, 5),\n",
    "        labels = [\"M_WDM\", \"OMm\", \"L_X\", \"NU_X_THRESH\", \"ION_Tvir_MIN\", \"HII_EFF_FACTOR\"],\n",
    "        points= y[idx]\n",
    "\n",
    "    )\n",
    "    \n",
    "    fig.savefig(f\"./NLE_{i}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataHandler(path=\"./data/\", prefix=\"batch\", load_to_ram=False,\n",
    "                         split = train_test_data_ration, training_data = True,\n",
    "                         apply_norm=True, norm_range=norm_range, augmentation_probability=.5)\n",
    "# import data to torch dataloader\n",
    "train_dataloader = DataLoader(train_data, batch_size=1, shuffle=True,\n",
    "                              num_workers = 2, pin_memory = True, prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dat in train_dataloader:\n",
    "    img, _,_ = dat\n",
    "    print(img.shape)\n",
    "    plt.imshow(img[0,0,:,:,0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand((100,100,100))\n",
    "%timeit noise1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 0 if 0 == 1 elif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi import utils, analysis\n",
    "\n",
    "from sbi.diagnostics import check_sbc, run_sbc\n",
    "from sbi.analysis import sbc_rank_plot\n",
    "import corner\n",
    "import numpy as np\n",
    "import arviz\n",
    "import pickle\n",
    "from sbi.inference.posteriors import MCMCPosterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../NRE_de.pkl\", \"rb\") as handle:\n",
    "    posterior = pickle.load(handle)\n",
    "\n",
    "posterior.potential_fn.device = 'cpu'\n",
    "posterior = MCMCPosterior(potential_fn=posterior.potential_fn,\n",
    "                          proposal=posterior.proposal,\n",
    "                          theta_transform=posterior.theta_transform,\n",
    "                          method='slice_np_vectorized',\n",
    "                          thin=posterior.thin,\n",
    "                          warmup_steps=posterior.warmup_steps,\n",
    "                          num_chains=6,\n",
    "                          num_workers=6,\n",
    "                          device='cpu')\n",
    "\n",
    "model = ModelHandler(Model = Summary_net_lc_super_smol, device=device)\n",
    "model.load_model(\"../NRE_sn.pt\")\n",
    "sum_net = model.Model\n",
    "\n",
    "with torch.no_grad():\n",
    "    with alive_bar(len(test_dataloader), force_tty=True, refresh_secs=1) as bar:\n",
    "        for i, (lab, img,_) in enumerate(test_dataloader):\n",
    "            img, lab = img.to(device), lab.to(device)\n",
    "            \n",
    "            if not i:\n",
    "                summary_vec = torch.empty(0,lab.shape[1], device=device)\n",
    "                labels = torch.empty(0,lab.shape[1], device=device)\n",
    "\n",
    "            pred = sum_net(img)\n",
    "            summary_vec = torch.cat((summary_vec, pred), dim=0)\n",
    "            labels = torch.cat((labels, lab), dim=0)\n",
    "            bar()\n",
    "\n",
    "xs = summary_vec\n",
    "thetas = labels\n",
    "num_sbc_runs = xs.shape[0]\n",
    "num_posterior_samples = num_sbc_runs\n",
    "\n",
    "#xs, thetas = model.full_inference(sbc_dataloader)\n",
    "\n",
    "ranks, dap_samples = run_sbc(\n",
    "    thetas, xs, posterior, num_posterior_samples=num_posterior_samples\n",
    ")\n",
    "\n",
    "check_stats = check_sbc(\n",
    "    ranks, thetas, dap_samples, num_posterior_samples=num_posterior_samples\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"kolmogorov-smirnov p-values \\ncheck_stats['ks_pvals'] = {check_stats['ks_pvals'].numpy()}\"\n",
    ")\n",
    "print(\n",
    "    f\"c2st accuracies \\ncheck_stats['c2st_ranks'] = {check_stats['c2st_ranks'].numpy()}\"\n",
    ")\n",
    "print(\n",
    "    f\"c2st accuracies \\ncheck_stats['c2st_ranks'] = {check_stats['c2st_ranks'].numpy()}\"\n",
    ")\n",
    "\n",
    "fig, ax = sbc_rank_plot(\n",
    "    ranks=ranks,\n",
    "    num_posterior_samples=num_posterior_samples,\n",
    "    plot_type=\"hist\",\n",
    "    num_bins=None,  # by passing None we use a heuristic for the number of bins.\n",
    "    parameter_labels = [r\"$M_\\text{WDM}$\", r\"$\\Omega_m$\", r\"$L_X$\", r\"$E_0$\", r\"$T_\\text{vir, ion}$\", r\"$\\zeta$\"],\n",
    ")\n",
    "\n",
    "fig.savefig(\"NRE_sbc_rank_maf_freezed_sum.png\", dpi=300)\n",
    "\n",
    "fig, ax = sbc_rank_plot(ranks, 1_000, plot_type=\"cdf\", parameter_labels=[r\"$M_\\text{WDM}$\", r\"$\\Omega_m$\", r\"$L_X$\", r\"$E_0$\", r\"$T_\\text{vir, ion}$\", r\"$\\zeta$\"],)\n",
    "fig.savefig(\"NRE_sbc_CDF_maf_freezed_sum.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.potential_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,_ in train_dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    breal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "data_x, data_y = torch.zeros(100,1,28, 28, 470), torch.zeros(100,6)\n",
    "dummy_idx = torch.zeros(100)\n",
    "\n",
    "for i in range(100):\n",
    "    if torch.rand(1).item()<0.5:\n",
    "        data_x[i] = torch.ones(1,28, 28, 470)\n",
    "        data_y[i] = torch.ones(6)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "train_test_data_ration = 0.9\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "optimizer_params = {\n",
    "    \"lr\": 1e-3,\n",
    "}\n",
    "\n",
    "loss = torch.nn.MSELoss\n",
    "loss_params = {}\n",
    "\n",
    "dataset_train = TensorDataset(data_y[:80], data_x[:80], dummy_idx[:80])\n",
    "dataset_test = TensorDataset(data_y[80:], data_x[80:], dummy_idx[80:])\n",
    "\n",
    "dataset_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataset_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "model = ModelHandler(Model = Summary_net_lc_super_smol,\n",
    "                     Training_data=dataset_train, Test_data=dataset_test, device=device)\n",
    "\n",
    "\n",
    "# train\n",
    "model.train(\n",
    "    epochs=epochs,\n",
    "    optimizer=optimizer(\n",
    "        model.Model.parameters(),\n",
    "        **optimizer_params),\n",
    "        lossf=loss(**loss_params))\n",
    "\n",
    "# test\n",
    "#model.test(Validation_data = test_dataloader, Model = model.Model, lossf=loss(**loss_params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
