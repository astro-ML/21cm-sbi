{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available:  True\n"
     ]
    }
   ],
   "source": [
    "from utility import *\n",
    "from models import * \n",
    "from dataloader import *\n",
    "my_module_path = os.path.join(\"../\", '21cm-wrapper')\n",
    "sys.path.append(my_module_path)\n",
    "from Leaf import *\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "#torch.set_num_interop_threads(4) # Inter-op parallelism\n",
    "#torch.set_num_threads(6) # Intra-op parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.zeros((10,10,10))\n",
    "print(not torch.any(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|███▌⚠︎                                   | (!) 90/1040 [9%] in 32.7s (2.79/s)   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconvert_to_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/potato/Documents/projects/master/data/data_smol/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimrun_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_for_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_zeros\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredshift_cutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m680\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/master/21cm-sbi/utility.py:108\u001b[0m, in \u001b[0;36mconvert_to_torch\u001b[0;34m(path, prefix, check_for_nan, debug, remove_zeros, redshift_cutoff, statistics)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# stuff good to know\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m statistics \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m     temp_lc \u001b[38;5;241m=\u001b[39m \u001b[43mp21c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLightCone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightcone_redshifts\u001b[49m\n\u001b[1;32m    109\u001b[0m     zlc\u001b[38;5;241m.\u001b[39mappend(temp_lc[redshift_cutoff])\n\u001b[1;32m    110\u001b[0m     zlc_min \u001b[38;5;241m=\u001b[39m temp_lc[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/py21cmfast/outputs.py:1223\u001b[0m, in \u001b[0;36mLightCone.lightcone_redshifts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlightcone_redshifts\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Redshift of each cell along the redshift axis.\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m-> 1223\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m            \u001b[49m\u001b[43mz_at_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosmo_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosmo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomoving_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightcone_distances\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1227\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/py21cmfast/outputs.py:1224\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlightcone_redshifts\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Redshift of each cell along the redshift axis.\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m   1223\u001b[0m         [\n\u001b[0;32m-> 1224\u001b[0m             \u001b[43mz_at_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosmo_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosmo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomoving_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightcone_distances\n\u001b[1;32m   1226\u001b[0m         ]\n\u001b[1;32m   1227\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/astropy/cosmology/funcs/optimize.py:393\u001b[0m, in \u001b[0;36mz_at_value\u001b[0;34m(func, fval, zmin, zmax, ztol, maxfun, method, bracket, verbose)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnditer(\n\u001b[1;32m    383\u001b[0m     [fval, zmin, zmax, ztol, maxfun, bracket, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[1;32m    384\u001b[0m     flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefs_ok\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    391\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m it:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fv, zmn, zmx, zt, mfe, bkt, zs \u001b[38;5;129;01min\u001b[39;00m it:  \u001b[38;5;66;03m# ← eltwise unpack & eval ↓\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m         zs[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_z_at_scalar_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mzmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzmn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mzmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzmx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mztol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmaxfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmfe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbracket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbkt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# not broadcasted\u001b[39;49;00m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# since bracket is an object array, the output will be too, so it is\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# cast to the same type as the function value.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m it\u001b[38;5;241m.\u001b[39moperands[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# zs\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/astropy/cosmology/funcs/optimize.py:95\u001b[0m, in \u001b[0;36m_z_at_scalar_value\u001b[0;34m(func, fval, zmin, zmax, ztol, maxfun, method, bracket, verbose)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(func(z) \u001b[38;5;241m-\u001b[39m val)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Perform the minimization\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mminimize_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbracket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbracket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Scipy docs state that `OptimizeResult` always has 'status' and 'message'\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# attributes, but only `_minimize_scalar_bounded()` seems to have really\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# implemented them.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res\u001b[38;5;241m.\u001b[39msuccess:\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/scipy/optimize/_minimize.py:960\u001b[0m, in \u001b[0;36mminimize_scalar\u001b[0;34m(fun, bracket, bounds, args, method, tol, options)\u001b[0m\n\u001b[1;32m    958\u001b[0m     res \u001b[38;5;241m=\u001b[39m method(fun, args\u001b[38;5;241m=\u001b[39margs, bracket\u001b[38;5;241m=\u001b[39mbracket, bounds\u001b[38;5;241m=\u001b[39mbounds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrent\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 960\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_recover_from_bracket_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_minimize_scalar_brent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbracket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbounded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:3059\u001b[0m, in \u001b[0;36m_recover_from_bracket_error\u001b[0;34m(solver, fun, bracket, args, **options)\u001b[0m\n\u001b[1;32m   3040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recover_from_bracket_error\u001b[39m(solver, fun, bracket, args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions):\n\u001b[1;32m   3041\u001b[0m     \u001b[38;5;66;03m# `bracket` was originally written without checking whether the resulting\u001b[39;00m\n\u001b[1;32m   3042\u001b[0m     \u001b[38;5;66;03m# bracket is valid. `brent` and `golden` built on top of it without\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3056\u001b[0m     \u001b[38;5;66;03m# storing the information needed by `minimize_scalar` in the error object,\u001b[39;00m\n\u001b[1;32m   3057\u001b[0m     \u001b[38;5;66;03m# and intercepting it here.\u001b[39;00m\n\u001b[1;32m   3058\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3059\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbracket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3060\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m BracketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3061\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:2662\u001b[0m, in \u001b[0;36m_minimize_scalar_brent\u001b[0;34m(func, brack, args, xtol, maxiter, disp, **unknown_options)\u001b[0m\n\u001b[1;32m   2659\u001b[0m brent \u001b[38;5;241m=\u001b[39m Brent(func\u001b[38;5;241m=\u001b[39mfunc, args\u001b[38;5;241m=\u001b[39margs, tol\u001b[38;5;241m=\u001b[39mtol,\n\u001b[1;32m   2660\u001b[0m               full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, maxiter\u001b[38;5;241m=\u001b[39mmaxiter, disp\u001b[38;5;241m=\u001b[39mdisp)\n\u001b[1;32m   2661\u001b[0m brent\u001b[38;5;241m.\u001b[39mset_bracket(brack)\n\u001b[0;32m-> 2662\u001b[0m \u001b[43mbrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2663\u001b[0m x, fval, nit, nfev \u001b[38;5;241m=\u001b[39m brent\u001b[38;5;241m.\u001b[39mget_result(full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2665\u001b[0m success \u001b[38;5;241m=\u001b[39m nit \u001b[38;5;241m<\u001b[39m maxiter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (np\u001b[38;5;241m.\u001b[39misnan(x) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(fval))\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:2504\u001b[0m, in \u001b[0;36mBrent.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2503\u001b[0m     u \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m rat\n\u001b[0;32m-> 2504\u001b[0m fu \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# calculate new output value\u001b[39;00m\n\u001b[1;32m   2505\u001b[0m funcalls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (fu \u001b[38;5;241m>\u001b[39m fx):                 \u001b[38;5;66;03m# if it's bigger than current\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/astropy/cosmology/funcs/optimize.py:90\u001b[0m, in \u001b[0;36m_z_at_scalar_value.<locals>.f\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.0e300\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m zmin \u001b[38;5;241m-\u001b[39m z)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fval_zmin, Quantity):\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m-\u001b[39m val)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(func(z) \u001b[38;5;241m-\u001b[39m val)\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/astropy/cosmology/flrw/base.py:1105\u001b[0m, in \u001b[0;36mFLRW.comoving_distance\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomoving_distance\u001b[39m(\u001b[38;5;28mself\u001b[39m, z):\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Comoving line-of-sight distance in Mpc at a given redshift.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m    The comoving distance along the line-of-sight between two objects\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;124;03m        Comoving distance in Mpc to each input redshift.\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_comoving_distance_z1z2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/astropy/cosmology/flrw/base.py:1123\u001b[0m, in \u001b[0;36mFLRW._comoving_distance_z1z2\u001b[0;34m(self, z1, z2)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_comoving_distance_z1z2\u001b[39m(\u001b[38;5;28mself\u001b[39m, z1, z2):\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Comoving line-of-sight distance in Mpc between redshifts ``z1`` and ``z2``.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \n\u001b[1;32m   1110\u001b[0m \u001b[38;5;124;03m    The comoving distance along the line-of-sight between two objects\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;124;03m        Comoving distance in Mpc between each input redshift.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_integral_comoving_distance_z1z2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/astropy/cosmology/flrw/base.py:1161\u001b[0m, in \u001b[0;36mFLRW._integral_comoving_distance_z1z2\u001b[0;34m(self, z1, z2)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_integral_comoving_distance_z1z2\u001b[39m(\u001b[38;5;28mself\u001b[39m, z1, z2):\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Comoving line-of-sight distance in Mpc between objects at redshifts ``z1`` and ``z2``.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \n\u001b[1;32m   1148\u001b[0m \u001b[38;5;124;03m    The comoving distance along the line-of-sight between two objects remains\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;124;03m        Comoving distance in Mpc between each input redshift.\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hubble_distance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_integral_comoving_distance_z1z2_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/astropy/units/quantity.py:1223\u001b[0m, in \u001b[0;36mQuantity.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnitsError:  \u001b[38;5;66;03m# let other try to deal with it\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m-> 1223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__mul__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/master/ml-venv/lib/python3.11/site-packages/astropy/units/quantity.py:671\u001b[0m, in \u001b[0;36mQuantity.__array_ufunc__\u001b[0;34m(self, function, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     arrays\u001b[38;5;241m.\u001b[39mappend(converter(input_) \u001b[38;5;28;01mif\u001b[39;00m converter \u001b[38;5;28;01melse\u001b[39;00m input_)\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# Call our superclass's __array_ufunc__\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__array_ufunc__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# If unit is None, a plain array is expected (e.g., comparisons), which\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# means we're done.\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# We're also done if the result was None (for method 'at') or\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# NotImplemented, which can happen if other inputs/outputs override\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# __array_ufunc__; hopefully, they can then deal with us.\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "convert_to_torch(path = \"/home/potato/Documents/projects/master/data/data_smol/\", prefix= \"simrun_\", check_for_nan=True,\n",
    "                  debug=False, remove_zeros=True, statistics=True, redshift_cutoff=680)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "data_path = \"/home/deck/Documents/masterstuff/data/datax5/\"\n",
    "batch_size = 32\n",
    "epochs = 120\n",
    "train_test_data_ration = 0.9\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "optimizer_params = {\n",
    "    \"lr\": 1e-3,\n",
    "}\n",
    "\n",
    "loss = torch.nn.MSELoss\n",
    "loss_params = {}\n",
    "\n",
    "norm_range = torch.tensor([\n",
    "            [0.3,10.0], # M_WDM\n",
    "            [0.2,0.4], # OMm\n",
    "            [38, 42], # L_X\n",
    "            [100, 1500], # NU_X_THRESH\n",
    "            [4, 5.3], # ION_Tvir_MIN\n",
    "            [10.0, 250.0], # HII_EFF_FACTOR\n",
    "], dtype = torch.float32)\n",
    "\n",
    "\n",
    "# transform trainingsdata\n",
    "# perhaps add check if file is there: continue + override option in the future\n",
    "#convert_to_torch(path = data_path, prefix=\"run\", redshift_cutoff=600, debug=False, statistics=True)\n",
    "\n",
    "# load data\n",
    "train_data = DataHandler(path=data_path, prefix=\"batch_\",\n",
    "                         split = train_test_data_ration, training_data = True,\n",
    "                         apply_norm=True, norm_range=norm_range, augmentation_probability=0.5)\n",
    "test_data = DataHandler(path=data_path, prefix=\"batch_\",\n",
    "                         split = train_test_data_ration, training_data = False,\n",
    "                         apply_norm=True, norm_range=norm_range, augmentation_probability=0)\n",
    "# import data to torch dataloader\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                              num_workers = 2, pin_memory = True, prefetch_factor=2)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=True,\n",
    "                             num_workers = 2, pin_memory = True, prefetch_factor=2)\n",
    "\n",
    "# init model\n",
    "model = ModelHandler(Model = Summary_net_lc_super_smol,\n",
    "                     Training_data=train_dataloader, Test_data=test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train\n",
    "model.train(\n",
    "    epochs=epochs,\n",
    "    optimizer=optimizer(\n",
    "        model.Model.parameters(),\n",
    "        **optimizer_params),\n",
    "        lossf=loss(**loss_params))\n",
    "\n",
    "# test\n",
    "model.test(Validation_data = test_dataloader, Model = model.Model, lossf=loss(**loss_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SNPE ###\n",
    "\n",
    "from sbi.utils.get_nn_models import (\n",
    "    posterior_nn,\n",
    ")  # For SNPE: posterior_nn(), SNLE: likelihood_nn(). For SNRE: classifier_nn()\n",
    "from sbi.inference import SNPE, SNLE\n",
    "from sbi import utils, analysis\n",
    "\n",
    "# load the summary model\n",
    "model = ModelHandler(Model = Summary_net_lc_super_smol, device=device)\n",
    "model.load_model(\"./summary_net2.pt\")\n",
    "\n",
    "prior = utils.BoxUniform(low=torch.zeros((6)), high=torch.ones((6)), device=device)\n",
    "\n",
    "# define the maf\n",
    "density_estimator_build_fun = posterior_nn(\n",
    "    model=\"maf\", hidden_features=60, num_transforms=6, z_score_theta='none',\n",
    "    z_score_x='none'\n",
    ")\n",
    "\n",
    "# train the maf\n",
    "inference = SNPE(prior=prior, density_estimator=density_estimator_build_fun, device=device)\n",
    "\n",
    "y,x,idx = train_dataloader.dataset()\n",
    "\n",
    "inference.append_simulations(y,y)\n",
    "\n",
    "inference.train_indices = [0]\n",
    "\n",
    "\n",
    "density_net, summary_net, statistics = inference.train(train_dataloader=train_dataloader,\n",
    "                                    test_dataloader=test_dataloader,\n",
    "                                    optimizer=optimizer,\n",
    "                                    optimizer_parameter=optimizer_params,\n",
    "                                    summary_net=model.Model,\n",
    "                                    train_summary_net_freezed_rounds=50,\n",
    "                                    stop_after_epochs=10,\n",
    "                                    max_num_epochs=0,\n",
    "                                    clip_max_norm=None)\n",
    "\n",
    "# sample the posterior using the first 3 parameters from the testset\n",
    "posterior = inference.build_posterior(density_net, prior=prior)\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    #idx = np.random.randint(0,x.shape[0])\n",
    "    idx = i\n",
    "    y,x,_ = test_dataloader.dataset.__getitem__(i)\n",
    "    y,x = y.unsqueeze(0), x.unsqueeze(0)\n",
    "    print(y.shape, x.shape)\n",
    "\n",
    "    x = x.to(device)\n",
    "    \n",
    "    x = summary_net(x)\n",
    "\n",
    "    posterior_samples = posterior.sample((10000,), x=x).to('cpu')\n",
    "\n",
    "    # plot posterior samples\n",
    "    fig, ax = analysis.pairplot(\n",
    "        posterior_samples, limits=[[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],], figsize=(5, 5),\n",
    "        labels = [\"M_WDM\", \"OMm\", \"L_X\", \"NU_X_THRESH\", \"ION_Tvir_MIN\", \"HII_EFF_FACTOR\"],\n",
    "        points= y\n",
    "\n",
    "    )\n",
    "    \n",
    "    fig.savefig(f\"./NPE_{i}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NRE ###\n",
    "\n",
    "\n",
    "from sbi.utils.get_nn_models import (\n",
    "    classifier_nn\n",
    ")  # For SNPE: posterior_nn(), SNLE: likelihood_nn(). For SNRE: classifier_nn()\n",
    "from sbi.inference import SNRE\n",
    "from sbi import utils, analysis\n",
    "\n",
    "# load the summary model\n",
    "model = ModelHandler(Model = Summary_net_lc_super_smol, device=device)\n",
    "model.load_model(\"./summary_net2.pt\")\n",
    "\n",
    "prior = utils.BoxUniform(low=torch.zeros((6)), high=torch.ones((6)), device=device)\n",
    "\n",
    "# define the maf\n",
    "ratio_estimator = classifier_nn(\n",
    "    model = 'resnet', z_score_x='none',  z_score_theta='none'\n",
    ")\n",
    "\n",
    "# train the maf\n",
    "inference = SNRE(prior=prior, device=device, classifier=ratio_estimator)\n",
    "\n",
    "y,x,idx = train_dataloader.dataset()\n",
    "\n",
    "inference.append_simulations(y,y)\n",
    "\n",
    "inference.train_indices = [0]\n",
    "\n",
    "density_net, summary_net, statistics = inference.train(train_dataloader=train_dataloader,\n",
    "                                    test_dataloader=test_dataloader,\n",
    "                                    optimizer=optimizer,\n",
    "                                    optimizer_parameter=optimizer_params,\n",
    "                                    summary_net=model.Model,\n",
    "                                    train_summary_net_freezed_rounds=50,\n",
    "                                    stop_after_epochs=10,\n",
    "                                    max_num_epochs=0,\n",
    "                                    clip_max_norm=None)\n",
    "\n",
    "# sample the posterior using the first 3 parameters from the testset\n",
    "posterior = inference.build_posterior(density_net, prior=prior)\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    #idx = np.random.randint(0,x.shape[0])\n",
    "    idx = i\n",
    "    y,x,_ = test_dataloader.dataset.__getitem__(i)\n",
    "    y,x = y.unsqueeze(0), x.unsqueeze(0)\n",
    "    print(y.shape, x.shape)\n",
    "\n",
    "    x = x.to(device)\n",
    "    \n",
    "    x = summary_net(x)\n",
    "\n",
    "    posterior_samples = posterior.sample((10000,), x=x).to('cpu')\n",
    "\n",
    "    # plot posterior samples\n",
    "    fig, ax = analysis.pairplot(\n",
    "        posterior_samples, limits=[[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],], figsize=(5, 5),\n",
    "        labels = [\"M_WDM\", \"OMm\", \"L_X\", \"NU_X_THRESH\", \"ION_Tvir_MIN\", \"HII_EFF_FACTOR\"],\n",
    "        points= y\n",
    "\n",
    "    )\n",
    "    \n",
    "    fig.savefig(f\"./NRE_{i}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.diagnostics import check_sbc, run_sbc\n",
    "from sbi.analysis import sbc_rank_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.utils.torchutils import repeat_rows\n",
    "from torch import eye, ones\n",
    "num_atoms=10\n",
    "\n",
    "y,x,_ = test_dataloader.dataset.__getitem__(0)\n",
    "y,x = y.unsqueeze(0), x.unsqueeze(0)\n",
    "print(y.shape, x.shape)\n",
    "x = model.Model(x)\n",
    "\n",
    "y1, x1,_ = test_dataloader.dataset.__getitem__(1)\n",
    "y1,x1 = y1.unsqueeze(0), x1.unsqueeze(0)\n",
    "x1 = model.Model(x1)\n",
    "\n",
    "y, x = torch.cat((y,y1)), torch.cat((x,x1))\n",
    "\n",
    "batch_size = y.shape[0]\n",
    "print(f'{batch_size=}')\n",
    "\n",
    "repeated_x = repeat_rows(x, num_atoms)\n",
    "print(f'{repeated_x=}')\n",
    "\n",
    "# Choose `1` or `num_atoms - 1` thetas from the rest of the batch for each x.\n",
    "probs = ones(batch_size, batch_size) * (1 - eye(batch_size)) / (batch_size - 1)\n",
    "print(f'{probs=}')\n",
    "\n",
    "choices = torch.multinomial(probs, num_samples=num_atoms - 1, replacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train\n",
    "model.train(\n",
    "    epochs=epochs,\n",
    "    optimizer=optimizer(\n",
    "        model.Model.parameters(),\n",
    "        **optimizer_params),\n",
    "        lossf=loss(**loss_params))\n",
    "\n",
    "# test\n",
    "model.test(Validation_data = test_dataloader, Model = model.Model, lossf=loss(**loss_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take closer look at test\n",
    "ModelHandler.test_specific(test_dataloader, model.Model, loss(**loss_params), 1, denormalize=test_data.denormalize)\n",
    "\n",
    "# save the model\n",
    "#model.save_model(name = \"summary_net.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import SNPE, SNLE\n",
    "from sbi import utils, analysis\n",
    "\n",
    "# define model hyperparemeter\n",
    "user_params = {\n",
    "\"HII_DIM\": 40,\n",
    "\"BOX_LEN\": 160,\n",
    "\"N_THREADS\": 2,\n",
    "\"USE_INTERPOLATION_TABLES\": True,\n",
    "\"PERTURB_ON_HIGH_RES\": True\n",
    "}\n",
    "\n",
    "flag_options = {\n",
    "\"INHOMO_RECO\": True,\n",
    "\"USE_TS_FLUCT\": True\n",
    "}\n",
    "\n",
    "#simparams = p21c.outputs.LightCone.read(\"./data/run_36690\")\n",
    "# load the simulator class\n",
    "Leaf_simulator = Leaf(debug=True, user_params=user_params, flag_options=flag_options, redshift = 5.5)\n",
    "\n",
    "# define the prior ranges (only need for denormalization!)\n",
    "prior_range = torch.tensor([\n",
    "            [0.3,10.0], # M_WDM\n",
    "            [0.2,0.4], # OMm\n",
    "            [38, 42], # L_X\n",
    "            [100, 1500], # NU_X_THRESH\n",
    "            [4, 5.3], # ION_Tvir_MIN\n",
    "            [10.0, 250.0], # HII_EFF_FACTOR\n",
    "], dtype = torch.float32)\n",
    "\n",
    "# define the prior (uniform prior in this case)\n",
    "prior = utils.BoxUniform(low=torch.zeros((6)), high=torch.ones((6)))\n",
    "\n",
    "\n",
    "'''# define the simulator\n",
    "def simulation(theta):\n",
    "    M_WDM, OMm, L_X, NU_X_THRESH, ION_Tvir_MIN, HII_EFF_FACTOR = theta\n",
    "    cosmo_params = {\n",
    "        \"OMm\": OMm.item()\n",
    "        }\n",
    "    astro_params = {\n",
    "        \"L_X\": L_X.item(),\n",
    "        \"NU_X_THRESH\": NU_X_THRESH.item(),\n",
    "        \"ION_Tvir_MIN\": ION_Tvir_MIN.item(),\n",
    "        \"HII_EFF_FACTOR\": HII_EFF_FACTOR.item(),\n",
    "        \"INHOMO_RECO\": True\n",
    "    }\n",
    "    global_params = {\n",
    "        \"M_WDM\": M_WDM.item()\n",
    "    }\n",
    "\n",
    "\n",
    "    return Model.fast_forward(torch.as_tensor(Leaf_simulator.run_lightcone(\n",
    "        save = False, sanity_check = True, filter_peculiar = False, debug=False,\n",
    "        astro_params = astro_params, global_params = global_params, cosmo_params = cosmo_params).brightness_temp, dtype=torch.float32))\n",
    "\n",
    "\n",
    "def simulator(theta: torch.FloatTensor, Model: object, threads: int = 1):\n",
    "    tshape = theta.shape\n",
    "    schwimmhalle = Pool(max_workers=threads, max_tasks_per_child=1, mp_context=get_context('spawn'))\n",
    "    runner = [params for params in theta]\n",
    "    result = []\n",
    "    with alive_bar(len(runner), force_tty=True) as bar: \n",
    "        with schwimmhalle as p:\n",
    "            data = p.map(simulation, runner)\n",
    "            for dat in data:\n",
    "                lc_bt = future.result()\n",
    "\n",
    "                dat.add_done_callback(bar())\n",
    "    return data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if simulator is working\n",
    "#prepare_for_sbi(prior = prior, simulator = simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define point of interest\n",
    "# [M_WDM, OMm, L_X, NU_X_THRESH, ION_Tvir_MIN, HII_EFF_FACTOR]\n",
    "x_o = torch.tensor([2, 0.30964144154550644, 40.0, 500.0, 4.69897, 30.0], dtype=torch.float32)\n",
    "\n",
    "# A PPC is performed after we trained or neural posterior\n",
    "posterior.set_default_x(x_o)\n",
    "\n",
    "# We draw theta samples from the posterior. This part is not in the scope of SBI\n",
    "if __name__ == '__main__':\n",
    "    posterior_samples = posterior.sample((5000,))\n",
    "\n",
    "# We use posterior theta samples to generate x data\n",
    "    x_pp = torch.as_tensor(simulator(theta = posterior_samples, Model = model, threads=6))\n",
    "\n",
    "# We verify if the observed data falls within the support of the generated data\n",
    "_ = analysis.pairplot(\n",
    "    samples=x_pp,\n",
    "    points=x_o\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SNLE ###\n",
    "\n",
    "from sbi.utils.get_nn_models import (\n",
    "    likelihood_nn,\n",
    ")  \n",
    "\n",
    "# load the summary model\n",
    "model = ModelHandler(Model = Summary_net_lc_smol, device='cpu')\n",
    "model.load_model(\"./summary_net.pt\")\n",
    "\n",
    "# define the maf\n",
    "density_estimator_build_fun = posterior_nn(\n",
    "    model=\"maf\", hidden_features=60, num_transforms=6\n",
    ")\n",
    "\n",
    "# do inference using a freezed summary model\n",
    "x,y = model.full_inference(train_dataloader)\n",
    "\n",
    "# train the maf\n",
    "inference = SNLE(prior=prior, density_estimator=density_estimator_build_fun)\n",
    "inference.append_simulations(y,x)\n",
    "density_estimator = inference.train()\n",
    "# infere test data\n",
    "x,y = model.full_inference(test_dataloader)\n",
    "\n",
    "# sample the posterior using the first 3 parameters from the testset\n",
    "posterior = inference.build_posterior(density_estimator, prior=prior)\n",
    "for i in range(3):\n",
    "    \n",
    "    #idx = np.random.randint(0,x.shape[0])\n",
    "    idx = i\n",
    "    posterior_samples = posterior.sample((10000,), x=x[idx,:], num_workers=10, method=\"slice_np_vectorized\", num_chains=10)\n",
    "\n",
    "    # plot posterior samples\n",
    "    fig, ax = analysis.pairplot(\n",
    "        posterior_samples, limits=[[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],], figsize=(5, 5),\n",
    "        labels = [\"M_WDM\", \"OMm\", \"L_X\", \"NU_X_THRESH\", \"ION_Tvir_MIN\", \"HII_EFF_FACTOR\"],\n",
    "        points= y[idx]\n",
    "\n",
    "    )\n",
    "    \n",
    "    fig.savefig(f\"./NLE_{i}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataHandler(path=\"./data/\", prefix=\"batch\", load_to_ram=False,\n",
    "                         split = train_test_data_ration, training_data = True,\n",
    "                         apply_norm=True, norm_range=norm_range, augmentation_probability=.5)\n",
    "# import data to torch dataloader\n",
    "train_dataloader = DataLoader(train_data, batch_size=1, shuffle=True,\n",
    "                              num_workers = 2, pin_memory = True, prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dat in train_dataloader:\n",
    "    img, _,_ = dat\n",
    "    print(img.shape)\n",
    "    plt.imshow(img[0,0,:,:,0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand((100,100,100))\n",
    "%timeit noise1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 0 if 0 == 1 elif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi import utils, analysis\n",
    "\n",
    "from sbi.diagnostics import check_sbc, run_sbc\n",
    "from sbi.analysis import sbc_rank_plot\n",
    "import corner\n",
    "import numpy as np\n",
    "import arviz\n",
    "import pickle\n",
    "from sbi.inference.posteriors import MCMCPosterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../NRE_de.pkl\", \"rb\") as handle:\n",
    "    posterior = pickle.load(handle)\n",
    "\n",
    "posterior.potential_fn.device = 'cpu'\n",
    "posterior = MCMCPosterior(potential_fn=posterior.potential_fn,\n",
    "                          proposal=posterior.proposal,\n",
    "                          theta_transform=posterior.theta_transform,\n",
    "                          method='slice_np_vectorized',\n",
    "                          thin=posterior.thin,\n",
    "                          warmup_steps=posterior.warmup_steps,\n",
    "                          num_chains=6,\n",
    "                          num_workers=6,\n",
    "                          device='cpu')\n",
    "\n",
    "model = ModelHandler(Model = Summary_net_lc_super_smol, device=device)\n",
    "model.load_model(\"../NRE_sn.pt\")\n",
    "sum_net = model.Model\n",
    "\n",
    "with torch.no_grad():\n",
    "    with alive_bar(len(test_dataloader), force_tty=True, refresh_secs=1) as bar:\n",
    "        for i, (lab, img,_) in enumerate(test_dataloader):\n",
    "            img, lab = img.to(device), lab.to(device)\n",
    "            \n",
    "            if not i:\n",
    "                summary_vec = torch.empty(0,lab.shape[1], device=device)\n",
    "                labels = torch.empty(0,lab.shape[1], device=device)\n",
    "\n",
    "            pred = sum_net(img)\n",
    "            summary_vec = torch.cat((summary_vec, pred), dim=0)\n",
    "            labels = torch.cat((labels, lab), dim=0)\n",
    "            bar()\n",
    "\n",
    "xs = summary_vec\n",
    "thetas = labels\n",
    "num_sbc_runs = xs.shape[0]\n",
    "num_posterior_samples = num_sbc_runs\n",
    "\n",
    "#xs, thetas = model.full_inference(sbc_dataloader)\n",
    "\n",
    "ranks, dap_samples = run_sbc(\n",
    "    thetas, xs, posterior, num_posterior_samples=num_posterior_samples\n",
    ")\n",
    "\n",
    "check_stats = check_sbc(\n",
    "    ranks, thetas, dap_samples, num_posterior_samples=num_posterior_samples\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"kolmogorov-smirnov p-values \\ncheck_stats['ks_pvals'] = {check_stats['ks_pvals'].numpy()}\"\n",
    ")\n",
    "print(\n",
    "    f\"c2st accuracies \\ncheck_stats['c2st_ranks'] = {check_stats['c2st_ranks'].numpy()}\"\n",
    ")\n",
    "print(\n",
    "    f\"c2st accuracies \\ncheck_stats['c2st_ranks'] = {check_stats['c2st_ranks'].numpy()}\"\n",
    ")\n",
    "\n",
    "fig, ax = sbc_rank_plot(\n",
    "    ranks=ranks,\n",
    "    num_posterior_samples=num_posterior_samples,\n",
    "    plot_type=\"hist\",\n",
    "    num_bins=None,  # by passing None we use a heuristic for the number of bins.\n",
    "    parameter_labels = [r\"$M_\\text{WDM}$\", r\"$\\Omega_m$\", r\"$L_X$\", r\"$E_0$\", r\"$T_\\text{vir, ion}$\", r\"$\\zeta$\"],\n",
    ")\n",
    "\n",
    "fig.savefig(\"NRE_sbc_rank_maf_freezed_sum.png\", dpi=300)\n",
    "\n",
    "fig, ax = sbc_rank_plot(ranks, 1_000, plot_type=\"cdf\", parameter_labels=[r\"$M_\\text{WDM}$\", r\"$\\Omega_m$\", r\"$L_X$\", r\"$E_0$\", r\"$T_\\text{vir, ion}$\", r\"$\\zeta$\"],)\n",
    "fig.savefig(\"NRE_sbc_CDF_maf_freezed_sum.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.potential_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,_ in train_dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    breal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "data_x, data_y = torch.zeros(100,1,28, 28, 470), torch.zeros(100,6)\n",
    "dummy_idx = torch.zeros(100)\n",
    "\n",
    "for i in range(100):\n",
    "    if torch.rand(1).item()<0.5:\n",
    "        data_x[i] = torch.ones(1,28, 28, 470)\n",
    "        data_y[i] = torch.ones(6)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "train_test_data_ration = 0.9\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "optimizer_params = {\n",
    "    \"lr\": 1e-3,\n",
    "}\n",
    "\n",
    "loss = torch.nn.MSELoss\n",
    "loss_params = {}\n",
    "\n",
    "dataset_train = TensorDataset(data_y[:80], data_x[:80], dummy_idx[:80])\n",
    "dataset_test = TensorDataset(data_y[80:], data_x[80:], dummy_idx[80:])\n",
    "\n",
    "dataset_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataset_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "model = ModelHandler(Model = Summary_net_lc_super_smol,\n",
    "                     Training_data=dataset_train, Test_data=dataset_test, device=device)\n",
    "\n",
    "\n",
    "# train\n",
    "model.train(\n",
    "    epochs=epochs,\n",
    "    optimizer=optimizer(\n",
    "        model.Model.parameters(),\n",
    "        **optimizer_params),\n",
    "        lossf=loss(**loss_params))\n",
    "\n",
    "# test\n",
    "#model.test(Validation_data = test_dataloader, Model = model.Model, lossf=loss(**loss_params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
